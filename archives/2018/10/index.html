<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Archives: 2018/10 | 一生あとで読んでろ</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="技術ブログ">
<meta property="og:type" content="website">
<meta property="og:title" content="一生あとで読んでろ">
<meta property="og:url" content="http://ntddk.github.io/archives/2018/10/index.html">
<meta property="og:site_name" content="一生あとで読んでろ">
<meta property="og:description" content="技術ブログ">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="一生あとで読んでろ">
<meta name="twitter:description" content="技術ブログ">
  
  
  <link href="//fonts.googleapis.com/css?family=Ubuntu" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  
</head>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">一生あとで読んでろ</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">技術ブログ</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="sub-nav">
        
          <a id="nav-home-icon" class="nav-icon" href="/"></a>
        
          <a id="nav-about-icon" class="nav-icon" href="/about"></a>
        
        
      </nav>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-the-art-of-de-obfuscation" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    
      <header class="article-header">
        
  
    <a class="article-title" href="/2018/10/15/the-art-of-de-obfuscation/">The Art of De-obfuscation</a>
  

      </header>
    
    <time class="article-date" datetime="2018-10-15T11:00:00.000Z" itemprop="datePublished">10-15-2018</time>
    
  </div>
  <div class="article-inner">
    <div class="article-entry" itemprop="articleBody">
      
        <p>Last week, I gave a talk at <a href="https://wakate.org/2018/07/28/51th-general/" target="_blank" rel="external">第51回 情報科学若手の会</a>.</p>
<script async class="speakerdeck-embed" data-id="d581afa782624a629964475fd0e0aa98" data-ratio="1.33333333333333" src="//speakerdeck.com/assets/embed.js"></script>

<p>I am pleased to be able to tell the relationship between the artisanship of reverse engineering and the principle of computer science. The questions asked at the site are as follows:</p>
<table>
<thead>
<tr>
<th>Q</th>
<th>A</th>
</tr>
</thead>
<tbody>
<tr>
<td>Does the “operation” here mean mathematical operation or anything else?</td>
<td>In this presentation, the word “operation” corresponds to assembly or BitVector operations.</td>
</tr>
<tr>
<td>How much advanced obfuscation is spreading?</td>
<td>Although it is not widely used in malware for masses, it is common in government-grade malware e.g. APT28.</td>
</tr>
</tbody>
</table>
<p>Also, I got the feedback:</p>
<p><blockquote class="twitter-tweet" data-conversation="none" data-lang="ja"><p lang="en" dir="ltr">Hello - We had done similar work on JEB in 2017 (plugins for our native decompilers) to perform: 1) opaque predicate remove (see <a href="https://t.co/pAp5dD25XL" target="_blank" rel="external">https://t.co/pAp5dD25XL</a>) and 2) CFG un-flattening (see <a href="https://t.co/3fl5Qpr4g7" target="_blank" rel="external">https://t.co/3fl5Qpr4g7</a>) – check out the videos.</p>&mdash; JEB Decompiler (@jebdec) <a href="https://twitter.com/jebdec/status/1049358773045751808?ref_src=twsrc%5Etfw" target="_blank" rel="external">2018年10月8日</a></blockquote><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<p>It sounds great.</p>
<p>In the 会, I’ve enjoyed discussing various topics related to information science:</p>
<ul>
<li><a href="http://polyhedral.info/" target="_blank" rel="external">Polyhedral optimization</a>, a method to optimize a certain kind of loop called SCoP using a linear algebra model.</li>
<li><a href="https://arxiv.org/abs/1809.04098" target="_blank" rel="external">The paper</a> about principle of adversarial examples focusing on Fourier basis functions.</li>
<li><a href="http://www.colm.net/open-source/ragel/" target="_blank" rel="external">Ragel</a>, the parser generator used in the Ruby community. It was news to me.</li>
<li>The hypothesis that the cerebellum may be using reinforcement learning.</li>
<li>The weakness of random number generator of Dragon Quest 4 (PS version).</li>
<li>About quantitative indicator of the beautiness of exploit code.</li>
<li>Some binary analysis platform written in Rust e.g. <a href="https://github.com/danleh/wasabi" target="_blank" rel="external">wasabi</a>, <a href="https://github.com/falconre/falcon" target="_blank" rel="external">falcon</a> and <a href="https://github.com/falconre/finch" target="_blank" rel="external">finch</a>.</li>
<li>The fact that <a href="https://pokemongo.gamepress.gg/s2-cells-foundation-pokemon-go-design" target="_blank" rel="external">Pokemon Go players are knowledgeable about Hilbert curve</a>.</li>
</ul>
<p>If these topics capture your interest, why don’t you join the next 会?</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ntddk.github.io/2018/10/15/the-art-of-de-obfuscation/" data-id="cjna5v32m001vul7tkcy1l16v" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/program-synthesis/">program synthesis</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/reversing/">reversing</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/symbolic-execution/">symbolic execution</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-picoctf-2018-dog-or-frog-write-up" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    
      <header class="article-header">
        
  
    <a class="article-title" href="/2018/10/12/picoctf-2018-dog-or-frog-write-up/">picoCTF 2018 Dog or Frog Write-up</a>
  

      </header>
    
    <time class="article-date" datetime="2018-10-12T11:00:00.000Z" itemprop="datePublished">10-12-2018</time>
    
  </div>
  <div class="article-inner">
    <div class="article-entry" itemprop="articleBody">
      
        <p>Thank you for telling me this problem, <a href="https://twitter.com/kumagi" target="_blank" rel="external">@kumagi</a>!</p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p><img src="/image/dog_or_frog/dog_or_frog.png" width="100%" height="100%"></p>
<p>Dog or Frog <code>2018shell2.picoctf.com:18318</code> is a classic task about adversarial examples. </p>
<p>The following files are given:</p>
<ul>
<li>model</li>
<li>solution template</li>
<li>notes</li>
<li>source</li>
</ul>
<p>In short, what we need to do is adding noise to given image and to lead the classifier to misrecognition.</p>
<h1 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h1><p>I wrote a patch to the solution template with reference to <a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-8-how-to-intentionally-trick-neural-networks-b55da32b7196" target="_blank" rel="external">the tutorial</a> and <a href="https://arxiv.org/abs/1412.6572" target="_blank" rel="external">the paper with well-known panda figure</a>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div></pre></td><td class="code"><pre><div class="line">--- solution_template.py	<span class="number">2018</span><span class="number">-10</span><span class="number">-04</span> <span class="number">03</span>:<span class="number">16</span>:<span class="number">03.024712745</span> +<span class="number">0900</span></div><div class="line">+++ solve.py	<span class="number">2018</span><span class="number">-10</span><span class="number">-04</span> <span class="number">03</span>:<span class="number">34</span>:<span class="number">32.474374810</span> +<span class="number">0900</span></div><div class="line"><span class="meta">@@ -1,13 +1,17 @@</span></div><div class="line"> <span class="keyword">from</span> keras.applications.mobilenet <span class="keyword">import</span> preprocess_input</div><div class="line"> <span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</div><div class="line"> <span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> img_to_array, array_to_img</div><div class="line">+<span class="keyword">from</span> keras.applications.mobilenet <span class="keyword">import</span> decode_predictions, preprocess_input</div><div class="line"> <span class="keyword">from</span> PIL <span class="keyword">import</span> Image</div><div class="line"> <span class="keyword">from</span> imagehash <span class="keyword">import</span> phash</div><div class="line">+<span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line">+<span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</div><div class="line"> </div><div class="line"> </div><div class="line"> IMAGE_DIMS = (<span class="number">224</span>, <span class="number">224</span>)</div><div class="line"> TREE_FROG_IDX = <span class="number">31</span></div><div class="line"> TREE_FROG_STR = <span class="string">"tree_frog"</span></div><div class="line">+THRESHOLD = <span class="number">0.95</span></div><div class="line"> </div><div class="line"> </div><div class="line"> <span class="comment"># I'm pretty sure I borrowed this function from somewhere, but cannot remember</span></div><div class="line"><span class="meta">@@ -46,7 +50,27 @@</span></div><div class="line">     model = load_model(model_path)</div><div class="line"> </div><div class="line">     <span class="comment"># <span class="doctag">TODO:</span> YOUR SOLUTION HERE</span></div><div class="line">+    model.summary()</div><div class="line"> </div><div class="line">+    cost_function = model.layers[<span class="number">-1</span>].output[<span class="number">0</span>, TREE_FROG_IDX]</div><div class="line">+    gradient_function = K.gradients(cost_function, model.layers[<span class="number">0</span>].input)[<span class="number">0</span>]</div><div class="line">+    grab_cost_and_gradients_from_model = K.function([model.layers[<span class="number">0</span>].input, K.learning_phase()], [cost_function, gradient_function])</div><div class="line">+</div><div class="line">+    cost = <span class="number">0.0</span></div><div class="line">+</div><div class="line">+    <span class="keyword">while</span> cost &lt; THRESHOLD:</div><div class="line">+        cost, gradients = grab_cost_and_gradients_from_model([test, <span class="number">0</span>])</div><div class="line">+</div><div class="line">+        test += <span class="number">0.007</span> * np.sign(gradients) </div><div class="line">+</div><div class="line">+        print(<span class="string">'&#123;&#125;: &#123;&#125;% confidence'</span>.format(TREE_FROG_STR, cost * <span class="number">100</span>))</div><div class="line">+</div><div class="line">+    print(<span class="string">'_'</span> * <span class="number">65</span>)</div><div class="line">+    preds = model.predict(test)</div><div class="line">+    _, label1, conf1 = decode_predictions(preds)[<span class="number">0</span>][<span class="number">0</span>]</div><div class="line">+    print(<span class="string">'&#123;&#125;: &#123;&#125;% confidence'</span>.format(label1, conf1 * <span class="number">100</span>))</div><div class="line">+    dec_preds = decode_predictions(preds)[<span class="number">0</span>]</div><div class="line">+    print(dec_preds)</div><div class="line"> </div><div class="line">     test = test.reshape((<span class="number">224</span>,<span class="number">224</span>,<span class="number">3</span>))</div><div class="line">     img = array_to_img(test)</div></pre></td></tr></table></figure>
<p>The meaning of this implementation is the formula below which adjusted to the given model:</p>
<p>$\tilde{\boldsymbol{x}} = \boldsymbol{x} + \epsilon \thinspace \text{sign} (\nabla_\boldsymbol{x} \text{Loss}(\boldsymbol{x}, y))$ where $y$ is a label.</p>
<p>Then I’ve got:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div></pre></td><td class="code"><pre><div class="line">$ python solve.py</div><div class="line">Using TensorFlow backend.</div><div class="line">2018-10-04 03:16:48.974593: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA</div><div class="line">/home/ntddk/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.</div><div class="line">  warnings.warn(&apos;No training configuration found in save file: &apos;</div><div class="line">_________________________________________________________________</div><div class="line">Layer (type)                 Output Shape              Param #   </div><div class="line">=================================================================</div><div class="line">input_1 (InputLayer)         (None, 224, 224, 3)       0         </div><div class="line">_________________________________________________________________</div><div class="line">conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         </div><div class="line">_________________________________________________________________</div><div class="line">conv1 (Conv2D)               (None, 112, 112, 32)      864       </div><div class="line">_________________________________________________________________</div><div class="line">conv1_bn (BatchNormalization (None, 112, 112, 32)      128       </div><div class="line">_________________________________________________________________</div><div class="line">conv1_relu (ReLU)            (None, 112, 112, 32)      0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      </div><div class="line">_________________________________________________________________</div><div class="line">conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      </div><div class="line">_________________________________________________________________</div><div class="line">conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         </div><div class="line">_________________________________________________________________</div><div class="line">global_average_pooling2d_1 ( (None, 1024)              0         </div><div class="line">_________________________________________________________________</div><div class="line">reshape_1 (Reshape)          (None, 1, 1, 1024)        0         </div><div class="line">_________________________________________________________________</div><div class="line">dropout (Dropout)            (None, 1, 1, 1024)        0         </div><div class="line">_________________________________________________________________</div><div class="line">conv_preds (Conv2D)          (None, 1, 1, 1000)        1025000   </div><div class="line">_________________________________________________________________</div><div class="line">act_softmax (Activation)     (None, 1, 1, 1000)        0         </div><div class="line">_________________________________________________________________</div><div class="line">reshape_2 (Reshape)          (None, 1000)              0         </div><div class="line">=================================================================</div><div class="line">Total params: 4,253,864</div><div class="line">Trainable params: 4,231,976</div><div class="line">Non-trainable params: 21,888</div><div class="line">_________________________________________________________________</div><div class="line">&quot;tree_frog&quot; 1.029875316971296e-09% confidence</div><div class="line">&quot;tree_frog&quot; 0.32490063458681107% confidence</div><div class="line">&quot;tree_frog&quot; 97.77554869651794% confidence</div></pre></td></tr></table></figure>
<p>The perturbated image:</p>
<p><img src="/image/dog_or_frog/trixi_frog.png" width="100%" height="100%"></p>
<p>The flag:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">picoCTF&#123;n0w_th4t3_4_g00d_girl_2d6d5288&#125;</div></pre></td></tr></table></figure>
<h1 id="Final-words"><a href="#Final-words" class="headerlink" title="Final words"></a>Final words</h1><p>The attack method used here is called fast gradient sign method. It is just like a “Hello, world!” in adversarial examples research. At this rate, machine learning might be also becoming an essential skill in CTF.</p>
<p>Further CTF tasks related to neural networks are below:</p>
<table>
<thead>
<tr>
<th>Task</th>
<th>CTF event</th>
</tr>
</thead>
<tbody>
<tr>
<td>foolme</td>
<td>BCTF 2017</td>
</tr>
<tr>
<td>adamtune</td>
<td>DEF CON CTF Qualifier 2018</td>
</tr>
<tr>
<td>Astral Mind</td>
<td>SwampCTF 2018</td>
</tr>
<tr>
<td>Pilgrim</td>
<td>SwampCTF 2018</td>
</tr>
</tbody>
</table>
<p>Let me know if there is anything else missing!</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ntddk.github.io/2018/10/12/picoctf-2018-dog-or-frog-write-up/" data-id="cjna5v32a001bul7tjfhtp111" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
  
</section>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 ntddk<br>
      <a href="https://github.com/ntddk/hexo-theme-jathena" target="_blank">JAthena</a> by <a href="https://ntddk.github.io" target="_blank">ntddk</a> | Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>
  </div>

<!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
</body>
</html>