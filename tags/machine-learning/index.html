<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Tag: machine learning | 一生あとで読んでろ</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="技術ブログ">
<meta property="og:type" content="website">
<meta property="og:title" content="一生あとで読んでろ">
<meta property="og:url" content="http://ntddk.github.io/tags/machine-learning/index.html">
<meta property="og:site_name" content="一生あとで読んでろ">
<meta property="og:description" content="技術ブログ">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="一生あとで読んでろ">
<meta name="twitter:description" content="技術ブログ">
  
  
  <link href="//fonts.googleapis.com/css?family=Ubuntu" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  
</head>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">一生あとで読んでろ</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">技術ブログ</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="sub-nav">
        
          <a id="nav-home-icon" class="nav-icon" href="/"></a>
        
          <a id="nav-about-icon" class="nav-icon" href="/about"></a>
        
        
      </nav>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-paper-gestalt-revisited-a-case-study-on-computer-security-conferences" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    
      <header class="article-header">
        
  
    <a class="article-title" href="/2017/12/24/paper-gestalt-revisited-a-case-study-on-computer-security-conferences/">Paper Gestalt Revisited: A Case Study on Computer Security Conferences</a>
  

      </header>
    
    <time class="article-date" datetime="2017-12-23T15:00:00.000Z" itemprop="datePublished">12-24-2017</time>
    
  </div>
  <div class="article-inner">
    <div class="article-entry" itemprop="articleBody">
      
        <p>HAI DOMO. This post is for <a href="https://qiita.com/advent-calendar/2017/musashino" target="_blank" rel="external">武蔵野 Advent Calendar 2017</a>.</p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>In May this year, I just started my career as an apprentice security researcher at 武蔵野某所．One of my job responsibilities is to write a “good” paper that enough to be accepted to top-tier (non-crypto) security conferences like following:</p>
<ul>
<li>IEEE S&amp;P (Oakland)</li>
<li>ACM CCS</li>
<li>NDSS</li>
<li>USENIX Security</li>
</ul>
<p>However, I am profoundly ignorant of cardinal rules of “good” security research and technical writing. ぜんぜんわからない．俺たちは雰囲気で研究をやっている．I thought I got to do something.</p>
<p>The joke paper entitled <a href="https://vision.cornell.edu/se3/wp-content/uploads/2014/09/gestalt.pdf" target="_blank" rel="external">Paper Gestalt</a>, distributed in CVPR’10, gave me a suggestion.</p>
<p>The key idea of the paper is that “good” paper might be distinguished by image recognition. だるくなってきた．時間がないので日本語で書きます．このジョーク論文では，論文を画像に変換，局所特徴量を抽出し，論文がトップカンファレンスにacceptされるかどうか判定する分類器が提案されている．仔細は<a href="http://d.hatena.ne.jp/n_hidekey/20120101/1325388164" target="_blank" rel="external">Paper Gestalt - n_hidekeyの日記</a>を参照されたい．かっこいい数式や図がある論文はそれっぽく見えてしまうよね，という話．</p>
<p>　そういうわけで，本稿ではPaper Gestaltを参考に，論文がセキュリティ系トップカンファレンスにacceptされるか判定する分類器を作成する．元論文ではAdaBoostを用いていたが，ここでは畳み込みニューラルネットを試す．</p>
<h1 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h1><p>　上述のカンファレンスにacceptされた論文4年分を正例，併設ワークショップにacceptされた論文同じく4年分をトップカンファレンスにrejectされた論文とみなして負例とする．負例には諸先輩方の論文が含まれていて，すみません，でもわかってくれると思うんです．</p>
<p>　さて一通りスクレイピングしたのち，ポスターやショートペーパーなど，4ページに満たないものを削除．キーノートやスライドも取り除く．重要なのはフルペーパーだからだ．結果，それぞれの論文数は以下の通り：</p>
<table>
<thead>
<tr>
<th>accepted</th>
<th>rejected</th>
</tr>
</thead>
<tbody>
<tr>
<td>1,266</td>
<td>794</td>
</tr>
</tbody>
</table>
<p>　正例のワードクラウド：</p>
<p><img src="/image/paper-gestalt-revisited/wordcloud_accepted.png"></p>
<p>　負例：</p>
<p><img src="/image/paper-gestalt-revisited/wordcloud_rejected.png"></p>
<p>　なんもわからん．</p>
<h1 id="Pre-processing"><a href="#Pre-processing" class="headerlink" title="Pre-processing"></a>Pre-processing</h1><p>　論文PDFを画像化する．</p>
<p>　論文PDFの各ページを横に並べ，20ページに満たない場合は白紙で埋める処理を施した．例：</p>
<p><img src="/image/paper-gestalt-revisited/preprocessed_image_1.png"></p>
<p>　見ての通り，USENIX系の本会議に通った論文にはかっこいい表紙が付いてくる．他の論文と体裁を合わせるため削除：</p>
<p><img src="/image/paper-gestalt-revisited/preprocessed_image_2.png"></p>
<p>　3時間ほどかけて全PDFをImageMagickで画像化，訓練用・検証用に半々で分割．</p>
<h1 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h1><p>　今回はベンチマークということでLeNet-5をほぼそのまま使う．いつもいつも手書き文字を認識させられるなど過酷な拷問を受けているやつ．</p>
<p><img src="/image/paper-gestalt-revisited/model.png" width="50%" height="50%"></p>
<p>　フレームワークはkeras. データが少数かつclass imbalancedであることを考慮して，<a href="https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html" target="_blank" rel="external">Building powerful image classification models using very little data</a>に倣い，augmentationをかけながら訓練することにした．具体的にはズームと水平方向への反転．その他各種パラメータについてはありがちな構成を雰囲気で決めている：</p>
<table>
<thead>
<tr>
<th>活性化関数</th>
<th>損失関数</th>
<th>最適化手法</th>
<th>Dropout</th>
<th>バッチサイズ</th>
<th>エポック</th>
<th>Early stopping</th>
</tr>
</thead>
<tbody>
<tr>
<td>ReLU</td>
<td>クロスエントロピー</td>
<td>RMSProp</td>
<td>50%</td>
<td>64</td>
<td>100</td>
<td>validation accuracy</td>
</tr>
</tbody>
</table>
<p>　本来ならネットワーク構成含め細かくチューニングすべきだが，手元のショボい計算機では投稿日までに計算が終わらなさそうだったため，<a href="https://github.com/hyperopt/hyperopt" target="_blank" rel="external">hyperopt/hyperopt</a>やそのkeras連携機能である<a href="https://github.com/maxpumperla/hyperas" target="_blank" rel="external">maxpumperla/hyperas</a>とか，そういったかっこいいテクニックは使っていない．すみません2.</p>
<h1 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h1><p>　Early stoppingが効いて16エポックで学習打ち止め．学習曲線：</p>
<p><img src="/image/paper-gestalt-revisited/learning_curve_accuracy.png" width="50%" height="50%"><br><img src="/image/paper-gestalt-revisited/learning_curve_loss.png" width="50%" height="50%"></p>
<p>　微妙．しかし自分が学生時代に国内研究会に投げた論文を投入したところ，</p>
<table>
<thead>
<tr>
<th>accepted</th>
<th>rejected</th>
<th>predict</th>
</tr>
</thead>
<tbody>
<tr>
<td>7.3411%</td>
<td>92.6589%</td>
<td>rejected</td>
</tr>
</tbody>
</table>
<p>とまあ正しく判定できているっぽいのでよしとしましょう．なにが正しく判定だ．俺を，馬鹿にしているのか．いま，様々なものに対して害意を抱いています．Saliency mapの可視化とかは気が向いたら．</p>
<h1 id="Final-Words"><a href="#Final-Words" class="headerlink" title="Final Words"></a>Final Words</h1><p>　ACM CCS’17のWelcome Slidesにありがたいことばが載っている：</p>
<script async class="speakerdeck-embed" data-slide="35" data-id="a5ca2b52d1a046d59b1bcc6f7e4ab6b9" data-ratio="1.77777777777778" src="//speakerdeck.com/assets/embed.js"></script>

<p>　つまりはそういうことです．小手先の浅知恵に逃げるものはなにをやってもだめ．やるぞ〜．</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ntddk.github.io/2017/12/24/paper-gestalt-revisited-a-case-study-on-computer-security-conferences/" data-id="cjkr035sl000wpv7tc14bt4cs" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-a-prayer-for-the-dying-antivirus" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    
      <header class="article-header">
        
  
    <a class="article-title" href="/2017/09/10/a-prayer-for-the-dying-antivirus/">死にゆくアンチウイルスへの祈り</a>
  

      </header>
    
    <time class="article-date" datetime="2017-09-10T08:15:00.000Z" itemprop="datePublished">09-10-2017</time>
    
  </div>
  <div class="article-inner">
    <div class="article-entry" itemprop="articleBody">
      
        <p>　<a href="https://connpass.com/event/62844/" target="_blank" rel="external">Security meets Machine Learning</a>という勉強会にて，上記のタイトルで発表した．資料はこちら：</p>
<script async class="speakerdeck-embed" data-id="5c63dce1d2494dfc9f068fe1c58eab41" data-ratio="1.33333333333333" src="//speakerdeck.com/assets/embed.js"></script>

<p>　謎の力が働いて会社からの発表になっておりますが，機械学習の研究をしているわけではありません．既存研究の再現実装を試みているとこれ中国語の部屋じゃんという気持ちになる．<br>　ともあれ，これまで各種資料はただSpeakerDeckに載せるだけだったのを今後はブログから一元的に参照できるようにします．</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ntddk.github.io/2017/09/10/a-prayer-for-the-dying-antivirus/" data-id="cjkr035s10001pv7tu4s38jlc" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-yakiniku-optimization" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    
      <header class="article-header">
        
  
    <a class="article-title" href="/2016/12/04/yakiniku-optimization/">焼肉最適化問題</a>
  

      </header>
    
    <time class="article-date" datetime="2016-12-04T14:59:59.000Z" itemprop="datePublished">12-04-2016</time>
    
  </div>
  <div class="article-inner">
    <div class="article-entry" itemprop="articleBody">
      
        <p>　本稿は<a href="http://www.adventar.org/calendars/1413" target="_blank" rel="external">SFC-RG Advent Calendar 2016</a>の4日目である．</p>
<h1 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h1><p>　あなたは研究の中間発表を終えて，今晩何を食べようか考えている．たしかに準備不足ではあったけれど，研究の前提をいまいち解さないファカルティの高飛車な質問にはうんざりしたし，今日くらいはパーッと気分転換したいものだ．そういうわけで，あなたは⊿館を飛び出して焼肉 ざんまい 湘南台店に行くことにした．</p>
<h1 id="組合せ最適化"><a href="#組合せ最適化" class="headerlink" title="組合せ最適化"></a>組合せ最適化</h1><p>　さて，着席し，メニューを開いたあなたはしばし考える．限られた予算，限られた時間，限られた胃袋の容量——いったい何を頼めば最も<strong>満足</strong>できるだろうか？<br>　そんなとき，組合せ最適化が役に立つんです．騙されたと思って，メニューを必死に転記してみよう：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np, pandas <span class="keyword">as</span> pd</div><div class="line"></div><div class="line">menu = [<span class="string">'カルビ'</span>, <span class="string">'和牛カルビ'</span>, <span class="string">'和牛中落ちカルビ'</span>, <span class="string">'ハラミ'</span>, <span class="string">'厚切りロース'</span>, <span class="string">'ネギ牛タン塩'</span>, <span class="string">'牛タン塩'</span>, </div><div class="line">        <span class="string">'イベリコ豚'</span>, <span class="string">'カシラ'</span>, <span class="string">'豚トロ'</span>, <span class="string">'ネギ豚タン塩'</span>, <span class="string">'豚タン塩'</span>, <span class="string">'厚切りベーコン'</span>, <span class="string">'ウインナー'</span>, <span class="string">'チョリソ'</span>, </div><div class="line">        <span class="string">'ホルモン'</span>, <span class="string">'シロコロホルモン'</span>, <span class="string">'レバー'</span>, <span class="string">'白レバー'</span>, <span class="string">'ハツ'</span>, <span class="string">'ミノ'</span>, </div><div class="line">        <span class="string">'お得!! 三種盛り'</span>, <span class="string">'本日の塩三種盛り'</span>, <span class="string">'本日の味噌三種盛り'</span>]</div><div class="line">price = [<span class="number">720</span>, <span class="number">950</span>, <span class="number">850</span>, <span class="number">720</span>, <span class="number">690</span>, <span class="number">950</span>, <span class="number">850</span>, </div><div class="line">        <span class="number">600</span>, <span class="number">550</span>, <span class="number">580</span>, <span class="number">680</span>, <span class="number">580</span>, <span class="number">500</span>, <span class="number">380</span>, <span class="number">400</span>, </div><div class="line">        <span class="number">550</span>, <span class="number">600</span>, <span class="number">550</span>, <span class="number">450</span>, <span class="number">550</span>, <span class="number">650</span>, </div><div class="line">        <span class="number">1280</span>, <span class="number">780</span>, <span class="number">780</span>]</div><div class="line"></div><div class="line">n = len(menu)</div><div class="line">np.random.seed(<span class="number">0</span>)</div><div class="line">df = pd.DataFrame(&#123;</div><div class="line">    <span class="string">'品目'</span>: menu,</div><div class="line">    <span class="string">'値段'</span>: price,</div><div class="line">    <span class="string">'満足度'</span>: np.random.randint(<span class="number">10</span>, <span class="number">20</span>, n),</div><div class="line">    <span class="string">'焼き時間'</span>: np.random.randint(<span class="number">5</span>, <span class="number">10</span>, n),</div><div class="line">    <span class="string">'量'</span>: np.random.randint(<span class="number">10</span>, <span class="number">20</span>, n),</div><div class="line">    &#125;)</div><div class="line"></div><div class="line">print(df)</div></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th></th>
<th>値段</th>
<th>品目</th>
<th>満足度</th>
<th>焼き時間</th>
<th>量</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>720</td>
<td>カルビ</td>
<td>15</td>
<td>9</td>
<td>10</td>
</tr>
<tr>
<td>1</td>
<td>950</td>
<td>和牛カルビ</td>
<td>10</td>
<td>8</td>
<td>10</td>
</tr>
<tr>
<td>2</td>
<td>850</td>
<td>和牛中落ちカルビ</td>
<td>13</td>
<td>5</td>
<td>14</td>
</tr>
<tr>
<td>3</td>
<td>720</td>
<td>ハラミ</td>
<td>13</td>
<td>8</td>
<td>15</td>
</tr>
<tr>
<td>4</td>
<td>690</td>
<td>厚切りロース</td>
<td>17</td>
<td>5</td>
<td>15</td>
</tr>
<tr>
<td>5</td>
<td>950</td>
<td>ネギ牛タン塩</td>
<td>19</td>
<td>7</td>
<td>16</td>
</tr>
<tr>
<td>6</td>
<td>850</td>
<td>牛タン塩</td>
<td>13</td>
<td>8</td>
<td>18</td>
</tr>
<tr>
<td>7</td>
<td>600</td>
<td>イベリコ豚</td>
<td>15</td>
<td>5</td>
<td>14</td>
</tr>
<tr>
<td>8</td>
<td>550</td>
<td>カシラ</td>
<td>12</td>
<td>6</td>
<td>11</td>
</tr>
<tr>
<td>9</td>
<td>580</td>
<td>豚トロ</td>
<td>14</td>
<td>8</td>
<td>14</td>
</tr>
<tr>
<td>10</td>
<td>680</td>
<td>ネギ豚タン塩</td>
<td>17</td>
<td>8</td>
<td>19</td>
</tr>
<tr>
<td>11</td>
<td>580</td>
<td>豚タン塩</td>
<td>16</td>
<td>8</td>
<td>18</td>
</tr>
<tr>
<td>12</td>
<td>500</td>
<td>厚切りベーコン</td>
<td>18</td>
<td>5</td>
<td>11</td>
</tr>
<tr>
<td>13</td>
<td>380</td>
<td>ウインナー</td>
<td>18</td>
<td>6</td>
<td>11</td>
</tr>
<tr>
<td>14</td>
<td>400</td>
<td>チョリソ</td>
<td>11</td>
<td>6</td>
<td>17</td>
</tr>
<tr>
<td>15</td>
<td>550</td>
<td>ホルモン</td>
<td>16</td>
<td>6</td>
<td>19</td>
</tr>
<tr>
<td>16</td>
<td>600</td>
<td>シロコロホルモン</td>
<td>17</td>
<td>5</td>
<td>19</td>
</tr>
<tr>
<td>17</td>
<td>550</td>
<td>レバー</td>
<td>17</td>
<td>7</td>
<td>13</td>
</tr>
<tr>
<td>18</td>
<td>450</td>
<td>白レバー</td>
<td>18</td>
<td>9</td>
<td>16</td>
</tr>
<tr>
<td>19</td>
<td>550</td>
<td>ハツ</td>
<td>11</td>
<td>8</td>
<td>17</td>
</tr>
<tr>
<td>20</td>
<td>650</td>
<td>ミノ</td>
<td>15</td>
<td>8</td>
<td>12</td>
</tr>
<tr>
<td>21</td>
<td>1280</td>
<td>お得!! 三種盛り</td>
<td>19</td>
<td>7</td>
<td>10</td>
</tr>
<tr>
<td>22</td>
<td>780</td>
<td>本日の塩三種盛り</td>
<td>18</td>
<td>9</td>
<td>13</td>
</tr>
<tr>
<td>23</td>
<td>780</td>
<td>本日の味噌三種盛り</td>
<td>19</td>
<td>7</td>
<td>15</td>
</tr>
</tbody>
</table>
<p>　メニューがpandasのデータフレームになった．取り急ぎ（？）満足度・焼き時間・量は乱数で埋めている．<br>　あなたはこのメニューの中から，最も満足度の高い組合せを見つけたい．それも，限られた予算，限られた時間，限られた胃袋の容量という条件を満たすような．ここではそのわがままを割当問題として解くことにする．</p>
<table>
<thead>
<tr>
<th>変数</th>
<th><span>$x_i \in \{0, 1\}$</span><!-- Has MathJax --></th>
<th>i番目の料理を選ぶかどうか</th>
</tr>
</thead>
<tbody>
<tr>
<td>目的関数</td>
<td><span>$\sum_i{満足度_i x_i}$</span><!-- Has MathJax --></td>
<td><span>$\rightarrow$</span><!-- Has MathJax --> 最大</td>
</tr>
<tr>
<td>制約条件</td>
<td><span>$\sum_i{予算_i x_i} \le 12000$</span><!-- Has MathJax --></td>
<td>予算制限</td>
</tr>
<tr>
<td></td>
<td><span>$\sum_i{焼き時間_i x_i} \le 120$</span><!-- Has MathJax --></td>
<td>時間制限</td>
</tr>
<tr>
<td></td>
<td><span>$150 \le \sum_i{量_i x_i} \le 200$</span><!-- Has MathJax --></td>
<td>分量制限</td>
</tr>
</tbody>
</table>
<p>　こういった問題はpulpという整数計画法ライブラリを使って解くことができる：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pulp <span class="keyword">import</span> *</div><div class="line"></div><div class="line">m = LpProblem(sense = LpMaximize)	<span class="comment"># 最大化問題</span></div><div class="line">df[<span class="string">'x'</span>] = [LpVariable(<span class="string">'x%d'</span> % i, cat = LpBinary) <span class="keyword">for</span> i <span class="keyword">in</span> range(n)]	<span class="comment"># i番目の品目を選択するかしないか</span></div><div class="line"></div><div class="line">m += lpDot(df.満足度, df.x)	<span class="comment"># 目的関数：満足度の最大化</span></div><div class="line">m += lpDot(df.値段, df.x) &lt;= <span class="number">12000</span>	<span class="comment"># 制約条件：予算</span></div><div class="line">m += lpDot(df.焼き時間, df.x) &lt;= <span class="number">120</span>	<span class="comment"># 制約条件：焼き時間</span></div><div class="line">m += lpDot(df.量, df.x) &gt;= <span class="number">150</span>	<span class="comment"># 制約条件：量</span></div><div class="line">m += lpDot(df.量, df.x) &lt;= <span class="number">200</span>	<span class="comment"># 制約条件：量</span></div><div class="line"></div><div class="line">m.solve()</div><div class="line"><span class="keyword">if</span> m.status == <span class="number">1</span>:</div><div class="line">    df[<span class="string">'val'</span>] = df.x.apply(<span class="keyword">lambda</span> v: value(v))	<span class="comment"># 結果</span></div><div class="line">    print(df[df.val == <span class="number">1</span>].品目)</div><div class="line">    print(<span class="string">'満足度 &#123;&#125;'</span>.format(sum(df[df.val == <span class="number">1</span>].満足度)))</div><div class="line">    print(<span class="string">'値段 &#123;&#125;'</span>.format(sum(df[df.val == <span class="number">1</span>].値段)))</div><div class="line"></div><div class="line">&gt;&gt;&gt;</div><div class="line"><span class="number">0</span>           カルビ</div><div class="line"><span class="number">4</span>        厚切りロース</div><div class="line"><span class="number">5</span>        ネギ牛タン塩</div><div class="line"><span class="number">7</span>         イベリコ豚</div><div class="line"><span class="number">8</span>           カシラ</div><div class="line"><span class="number">9</span>           豚トロ</div><div class="line"><span class="number">12</span>      厚切りベーコン</div><div class="line"><span class="number">13</span>        ウインナー</div><div class="line"><span class="number">16</span>     シロコロホルモン</div><div class="line"><span class="number">17</span>          レバー</div><div class="line"><span class="number">18</span>         白レバー</div><div class="line"><span class="number">20</span>           ミノ</div><div class="line"><span class="number">21</span>    お得!! 三種盛り</div><div class="line"><span class="number">22</span>     本日の塩三種盛り</div><div class="line"><span class="number">23</span>    本日の味噌三種盛り</div><div class="line">Name: 品目, dtype: object</div><div class="line">満足度 <span class="number">251</span></div><div class="line">値段 <span class="number">10060</span></div></pre></td></tr></table></figure>
<p>　はい．順番はともかくとして，これらを食べれば満足できそうだ．<br>　ここまで考えたところで，あなたは今月の懐具合がよろしくないことを思い出す．なるべく出費を抑えて，それでいてある程度満足できるような品目の組合せはあるだろうか？<br>　これも同様に割当問題として考えられる．</p>
<table>
<thead>
<tr>
<th>変数</th>
<th><span>$x_i \in \{0, 1\}$</span><!-- Has MathJax --></th>
<th>i番目の料理を選ぶかどうか</th>
</tr>
</thead>
<tbody>
<tr>
<td>目的関数</td>
<td><span>$\sum_i{予算_i x_i}$</span><!-- Has MathJax --></td>
<td><span>$\rightarrow$</span><!-- Has MathJax --> 最小</td>
</tr>
<tr>
<td>制約条件</td>
<td><span>$\sum_i{満足度_i x_i} \le 200$</span><!-- Has MathJax --></td>
<td>満足度制限</td>
</tr>
<tr>
<td></td>
<td><span>$\sum_i{焼き時間_i x_i} \le 120$</span><!-- Has MathJax --></td>
<td>時間制限</td>
</tr>
<tr>
<td></td>
<td><span>$150 \le \sum_i{量_i x_i} \le 200$</span><!-- Has MathJax --></td>
<td>分量制限</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">m = LpProblem(sense = LpMinimize)	<span class="comment"># 最小化問題</span></div><div class="line">a[<span class="string">'v'</span>] = [LpVariable(<span class="string">'v%d'</span> % i, cat = LpBinary) <span class="keyword">for</span> i <span class="keyword">in</span> range(n)]	<span class="comment"># i番目の品目を選択するかしないか</span></div><div class="line"></div><div class="line">m += lpDot(df.値段, df.x)	<span class="comment"># 目的関数：予算の最小化</span></div><div class="line">m += lpDot(df.満足度, df.x) &gt;= <span class="number">200</span>	<span class="comment"># 制約条件：満足度</span></div><div class="line">m += lpDot(df.焼き時間, df.x) &lt;= <span class="number">120</span>	<span class="comment"># 制約条件：焼き時間</span></div><div class="line">m += lpDot(df.量, df.x) &gt;= <span class="number">150</span>	<span class="comment"># 制約条件：量</span></div><div class="line">m += lpDot(df.量, df.x) &lt;= <span class="number">200</span>	<span class="comment"># 制約条件：量</span></div><div class="line">m.solve()</div><div class="line"><span class="keyword">if</span> m.status == <span class="number">1</span>:</div><div class="line">    df[<span class="string">'val'</span>] = df.x.apply(<span class="keyword">lambda</span> v: value(v))	<span class="comment"># 結果</span></div><div class="line">    print(df[df.val == <span class="number">1</span>].品目)</div><div class="line">    print(<span class="string">'満足度 &#123;&#125;'</span>.format(sum(df[df.val == <span class="number">1</span>].満足度)))</div><div class="line">    print(<span class="string">'値段 &#123;&#125;'</span>.format(sum(df[df.val == <span class="number">1</span>].値段)))</div><div class="line"></div><div class="line">&gt;&gt;&gt;</div><div class="line"><span class="number">7</span>         イベリコ豚</div><div class="line"><span class="number">10</span>       ネギ豚タン塩</div><div class="line"><span class="number">11</span>         豚タン塩</div><div class="line"><span class="number">12</span>      厚切りベーコン</div><div class="line"><span class="number">13</span>        ウインナー</div><div class="line"><span class="number">14</span>         チョリソ</div><div class="line"><span class="number">15</span>         ホルモン</div><div class="line"><span class="number">16</span>     シロコロホルモン</div><div class="line"><span class="number">17</span>          レバー</div><div class="line"><span class="number">18</span>         白レバー</div><div class="line"><span class="number">22</span>     本日の塩三種盛り</div><div class="line"><span class="number">23</span>    本日の味噌三種盛り</div><div class="line">Name: 品目, dtype: object</div><div class="line">満足度 <span class="number">200</span></div><div class="line">値段 <span class="number">6850</span></div></pre></td></tr></table></figure>
<p>　200の満足度でいいなら豚ばっか食ってろということらしい．</p>
<h1 id="多腕バンディット問題"><a href="#多腕バンディット問題" class="headerlink" title="多腕バンディット問題"></a>多腕バンディット問題</h1><p>　いやいやちょっと待った．乱数でお茶を濁しているけど，あらゆる品目の満足度なんて知らないじゃないか．全品目を食べたことがあるならいざ知らず．それに，毎日同じ店で同じ食事をとるわけでもない．焼肉屋にしたって，湘南台には寅屋にえのもとにとあるわけだ．<br>　そういうわけで，あなたはいろいろな店に行き，いろいろな注文をして，なるべくどれを頼んでも満足度の高い食事のとれる店を見つけたいと考えた．しかしここで疑念が生まれる——いまの店でそこそこ満足できるなら，別の店を探さなくてもよいのではないか？ しかしいまの店に行き続ける限り，別の店の食事を食べることはできないぞ．しかしそこがハズレだとしたら．さてどうしよう——業界用語でこれを<strong>探索</strong>と<strong>利用</strong>のトレードオフ (exploration-exploitation tradeoff) という．</p>
<blockquote>
<p>これまでの学習結果を利用 (exploitation) しようとすると，探索 (exploration) が減ってしまい，機会損失が増えてしまう．一方，探索を増やせば，学習した最良の行動とは異なる行動をとることが増えるため，得られる報酬が減ってしまう．学習した最良の行動との差が，探索のコストということになる．– 牧野，et al. 『<a href="https://www.amazon.co.jp/dp/4627880316" target="_blank" rel="external">これからの強化学習</a>』</p>
</blockquote>
<p>　このトレードオフを解消する試みを多腕バンディット問題という．多腕バンディット問題は，複数のスロットマシンのレバー（腕）を次々と引いていき，最終的に得られる報酬を最大化するというもので，強化学習の一種といえる．各スロットマシンの報酬はそれぞれ一定の確率分布に従っている．言い換えれば，いろいろな店のメニューにある品目を試していき，最終的に得られる満足度を最大化していく，ということになる．もちろん，品目によって得られる満足度に違いはあるが，なるべく何を食べても満足度の高い店を絞り込んでいきたい．<br>　そのためのアルゴリズムのうち，ここでは<span>$\epsilon$</span><!-- Has MathJax -->-GreedyとUCB1を紹介したい．</p>
<h2 id="Greedy"><a href="#Greedy" class="headerlink" title="-Greedy"></a><span>$\epsilon$</span><!-- Has MathJax -->-Greedy</h2><p>　デフォルトで現在最良な選択肢を選ぶが，一定の確率でいま最良と思っていないような選択肢を選びにいく手法．</p>
<ul>
<li><span>$1 - \epsilon$</span><!-- Has MathJax -->の確率で最適だと思われる選択肢を利用する</li>
<li><span>$\epsilon / 2$</span><!-- Has MathJax -->の確率で最適だと思われる選択肢を探索する</li>
<li><span>$\epsilon / 2$</span><!-- Has MathJax -->の確率で最悪だと思われる選択肢を探索する</li>
</ul>
<p>　<span>$\epsilon$</span><!-- Has MathJax -->-Greedyはつまり行きつけの店に入り浸るタイプのアルゴリズムだ．ただし<span>$0 &lt; \epsilon &lt; 1$</span><!-- Has MathJax -->.</p>
<h2 id="UCB1"><a href="#UCB1" class="headerlink" title="UCB1"></a>UCB1</h2><p>　それもいいが，実はいまの行きつけよりもっといい店なのに，一度行って微妙だったからといって行かないままになっている店がないだろうか？ UCB1は，それぞれの店についてどれくらい知っているかを考慮に入れ，なるべく多くの店のことを知ろうとするアルゴリズムだ．具体的には，各店（腕）についてUCB (Upper Confidence Bound) という値を計算する．</p>
<p>　<span>$\overline {x}_{j}+c\sqrt {\dfrac {2\log n} {x_{j}}}$</span><!-- Has MathJax --></p>
<p>　ただし<span>$\overline {x}_{j}$</span><!-- Has MathJax -->は<span>$_{j}$</span><!-- Has MathJax -->番目の店の満足度（報酬）の期待値，<span>$n$</span><!-- Has MathJax -->はそれまでに店を回った回数の合計，<span>$n_{j}$</span><!-- Has MathJax -->は<span>$_{j}$</span><!-- Has MathJax -->番目の店に行った回数，<span>$c$</span><!-- Has MathJax -->は定数．UCB1は，この値が最大になる店に飛び込んでいく．あなたが好奇心旺盛なら，こちらのアルゴリズムを使って考えたほうがいいだろう．<br>　この手法のメリットとして，ベストでない店に行く回数を確率<span>$1$</span><!-- Has MathJax -->で<span>$O(\log n)$</span><!-- Has MathJax -->以内に抑えられる．長々とした証明は<a href="http://homes.di.unimi.it/~cesabian/Pubblicazioni/ml-02.pdf" target="_blank" rel="external">論文</a>を参照していただくとして，これは店に行く回数が十分大きい場合の理論限界に到達している．デメリットとしては，探索のためによくない店にあたってしまうことが多いという点が挙げられる．</p>
<h2 id="実験"><a href="#実験" class="headerlink" title="実験"></a>実験</h2><p>　では，<span>$\epsilon$</span><!-- Has MathJax -->-GreedyとUCB1が<strong>最良の店を選ぶ過程</strong>はどうなっているだろうか？ 『<a href="http://www.oreilly.co.jp/books/9784873116273/" target="_blank" rel="external">バンディットアルゴリズムによる最適化手法</a>』の<a href="https://github.com/johnmyleswhite/BanditsBook" target="_blank" rel="external">サンプルコード</a>をPython3 + numpy向けに改変して実験．</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> random</div><div class="line"><span class="keyword">import</span> math</div><div class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">BernoulliArm</span><span class="params">()</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, p)</span>:</span></div><div class="line">        self.p = p</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">draw</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">if</span> random.random() &gt; self.p:</div><div class="line">            <span class="keyword">return</span> <span class="number">0.0</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">return</span> <span class="number">1.0</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">EpsilonGreedy</span><span class="params">()</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, epsilon, counts, values)</span>:</span></div><div class="line">        self.epsilon = epsilon</div><div class="line">        self.counts = counts</div><div class="line">        self.values = values</div><div class="line">        <span class="keyword">return</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initialize</span><span class="params">(self, n_arms)</span>:</span></div><div class="line">        self.counts = np.zeros(n_arms)</div><div class="line">        self.values = np.zeros(n_arms)</div><div class="line">        <span class="keyword">return</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">select_arm</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">if</span> random.random() &gt; self.epsilon:</div><div class="line">            <span class="keyword">return</span> np.argmax(self.values)</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">return</span> np.random.randint(<span class="number">0</span>, len(self.values))</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update</span><span class="params">(self, chosen_arm, reward)</span>:</span></div><div class="line">        self.counts[chosen_arm] += <span class="number">1</span></div><div class="line">        n = self.counts[chosen_arm]</div><div class="line"></div><div class="line">        value = self.values[chosen_arm]</div><div class="line">        new_value = ((n<span class="number">-1</span>) / float(n)) * value + (<span class="number">1</span> / float(n)) * reward</div><div class="line">        self.values[chosen_arm] = new_value</div><div class="line">        <span class="keyword">return</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">UCB1</span><span class="params">()</span>:</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, counts, values)</span>:</span></div><div class="line">    self.counts = counts</div><div class="line">    self.values = values</div><div class="line">    <span class="keyword">return</span></div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">initialize</span><span class="params">(self, n_arms)</span>:</span></div><div class="line">    self.counts = np.zeros(n_arms)</div><div class="line">    self.values = np.zeros(n_arms)</div><div class="line">    <span class="keyword">return</span></div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">select_arm</span><span class="params">(self)</span>:</span></div><div class="line">    n_arms = len(self.counts)</div><div class="line">    <span class="keyword">for</span> arm <span class="keyword">in</span> range(n_arms):</div><div class="line">      <span class="keyword">if</span> self.counts[arm] == <span class="number">0</span>:</div><div class="line">        <span class="keyword">return</span> arm</div><div class="line"></div><div class="line">    ucb_values = [<span class="number">0.0</span> <span class="keyword">for</span> arm <span class="keyword">in</span> range(n_arms)]</div><div class="line">    total_counts = sum(self.counts)</div><div class="line">    <span class="keyword">for</span> arm <span class="keyword">in</span> range(n_arms):</div><div class="line">      bonus = math.sqrt((<span class="number">2</span> * math.log(total_counts)) / float(self.counts[arm]))</div><div class="line">      ucb_values[arm] = self.values[arm] + bonus</div><div class="line">    <span class="keyword">return</span> np.argmax(ucb_values)</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">update</span><span class="params">(self, chosen_arm, reward)</span>:</span></div><div class="line">    self.counts[chosen_arm] = self.counts[chosen_arm] + <span class="number">1</span></div><div class="line">    n = self.counts[chosen_arm]</div><div class="line"></div><div class="line">    value = self.values[chosen_arm]</div><div class="line">    new_value = ((n - <span class="number">1</span>) / float(n)) * value + (<span class="number">1</span> / float(n)) * reward</div><div class="line">    self.values[chosen_arm] = new_value</div><div class="line">    <span class="keyword">return</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_algorithm</span><span class="params">(algo, arms, num_sims, horizon)</span>:</span></div><div class="line">    chosen_arms = np.zeros(num_sims * horizon)</div><div class="line">    rewards = np.zeros(num_sims * horizon)</div><div class="line">    cumulative_rewards = np.zeros(num_sims * horizon)</div><div class="line">    sim_nums = np.zeros(num_sims * horizon)</div><div class="line">    times = np.zeros(num_sims * horizon)</div><div class="line"></div><div class="line">    <span class="keyword">for</span> sim <span class="keyword">in</span> range(num_sims):</div><div class="line">        sim += <span class="number">1</span></div><div class="line">        algo.initialize(len(arms))</div><div class="line"></div><div class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> range(horizon):</div><div class="line">            t += <span class="number">1</span></div><div class="line">            index = (sim - <span class="number">1</span>) * horizon + t - <span class="number">1</span></div><div class="line">            sim_nums[index] = sim</div><div class="line">            times[index] = t</div><div class="line"></div><div class="line">            chosen_arm = algo.select_arm()</div><div class="line">            chosen_arms[index] = chosen_arm</div><div class="line"></div><div class="line">            reward = arms[chosen_arm].draw()</div><div class="line">            rewards[index] = reward</div><div class="line"></div><div class="line">            <span class="keyword">if</span> t == <span class="number">1</span>:</div><div class="line">                cumulative_rewards[index] = reward</div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                cumulative_rewards[index] = cumulative_rewards[index - <span class="number">1</span>] + reward</div><div class="line"></div><div class="line">            algo.update(chosen_arm, reward)</div><div class="line"></div><div class="line">    <span class="keyword">return</span> [sim_nums, times, chosen_arms, rewards, cumulative_rewards]</div><div class="line"></div><div class="line">means = np.array([<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.9</span>])</div><div class="line">n_arms = len(means) <span class="comment"># 腕は5本</span></div><div class="line">random.shuffle(means)</div><div class="line"></div><div class="line">arms = [BernoulliArm(x) <span class="keyword">for</span> x <span class="keyword">in</span> means]</div><div class="line"></div><div class="line"><span class="keyword">for</span> epsilon <span class="keyword">in</span> [<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.5</span>]: <span class="comment"># epsilonを変えたらどうなるか？</span></div><div class="line">    algo = EpsilonGreedy(epsilon, [], [])</div><div class="line">    algo.initialize(n_arms)</div><div class="line">    results = test_algorithm(algo, arms, <span class="number">5000</span>, <span class="number">500</span>)</div><div class="line"></div><div class="line">    df = pd.DataFrame(&#123;<span class="string">"times"</span>: results[<span class="number">1</span>], <span class="string">"rewards"</span>: results[<span class="number">3</span>]&#125;)</div><div class="line">    grouped = df[<span class="string">"rewards"</span>].groupby(df[<span class="string">"times"</span>])</div><div class="line"></div><div class="line">    plt.plot(grouped.mean(), label=<span class="string">"epsilon="</span>+str(epsilon))</div><div class="line"></div><div class="line">algo = UCB1([], [])</div><div class="line">algo.initialize(n_arms)</div><div class="line">results = test_algorithm(algo, arms, <span class="number">5000</span>, <span class="number">500</span>)</div><div class="line"></div><div class="line">df = pd.DataFrame(&#123;<span class="string">"times"</span>: results[<span class="number">1</span>], <span class="string">"rewards"</span>: results[<span class="number">3</span>]&#125;)</div><div class="line">grouped = df[<span class="string">"rewards"</span>].groupby(df[<span class="string">"times"</span>])</div><div class="line"></div><div class="line">plt.plot(grouped.mean(), label=<span class="string">"UCB1"</span>)</div><div class="line"></div><div class="line">plt.legend(loc=<span class="string">"best"</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<p><img src="/image/bandits/bandits.png"></p>
<p>　好奇心旺盛な人は序盤それなりに苦労することがわかる．</p>
<h1 id="おわりに"><a href="#おわりに" class="headerlink" title="おわりに"></a>おわりに</h1><p>　こうしたナイーブな実装で焼肉の頼み方を最適化したり，店の巡り方を最適化できるかどうかというとまあ実際微妙（たとえば焼肉の各品目から得られる満足度は，限界効用逓減の法則に従ってすり減っていく）だが，日々の意思決定をアルゴリズム的に考えてみる遊びはそれなりにおもしろい．ソーシャルゲームにどう課金するか，というのもこの俎上に載せられる．<br>　『<a href="https://www.amazon.co.jp/dp/B015CKNWJI/" target="_blank" rel="external">Algorithms to Live By: The Computer Science of Human Decisions</a>』という本はそういう，情報系の人間がよくやる与太話をまじめに考察したものだ——書類はどのキャッシュアルゴリズムに従って並べるべきかとか．先に挙げた探索と利用のトレードオフについても述べられている．YouTubeで著者らの講演を観てほしい．</p>
<center><iframe width="560" height="315" src="https://www.youtube.com/embed/OwKj-wgXteo" frameborder="0" allowfullscreen></iframe></center>

<p>　はい．</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a href="http://qiita.com/Tsutomu-KKE@github/items/f8be15f56cbacdbb7bd9" target="_blank" rel="external">献立を組合せ最適化で考える - Qiita</a></li>
<li><a href="http://qiita.com/makora9143/items/9e90a533c95c24b85a94" target="_blank" rel="external">備忘録＠Python ORセミナー: Pulp - Qiita</a></li>
<li><a href="http://qiita.com/yuku_t/items/6844aac6008911401b19" target="_blank" rel="external">A/Bテストよりすごい？バンディットアルゴリズムとは一体何者か - Qiita</a></li>
<li><a href="http://minerva.cs.uec.ac.jp/~ito/entcog/contents/lecture/date/5-yoshizoe.pdf" target="_blank" rel="external">コンピュータ囲碁における モンテカルロ法 ~理論編~[PDF]</a></li>
</ul>
<h1 id="追記-2016-12-06"><a href="#追記-2016-12-06" class="headerlink" title="追記 (2016.12.06)"></a>追記 (2016.12.06)</h1><p>　今回のような設定では多腕バンディット問題というより最適腕識別として考えたほうがよさそう．多腕バンディット問題は累積報酬の最大化が目的だけれど，最適腕識別はどの腕が最良か発見するのが目的．将来の報酬が最大の腕を見つける，ということ．『<a href="https://www.amazon.co.jp/dp/406152917X/" target="_blank" rel="external">バンディット問題の理論とアルゴリズム</a>』を読めばいいんだとか．</p>
<h1 id="追記-2018-08-13"><a href="#追記-2018-08-13" class="headerlink" title="追記 (2018.08.13)"></a>追記 (2018.08.13)</h1><p>　<span>$\epsilon - 1$</span><!-- Has MathJax -->となっていたのを<span>$1 - \epsilon$</span><!-- Has MathJax -->に修正．</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ntddk.github.io/2016/12/04/yakiniku-optimization/" data-id="cjkr035t40026pv7tr3fhxilg" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/optimization/">optimization</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-kdd-cup-99-data" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    
      <header class="article-header">
        
  
    <a class="article-title" href="/2016/11/23/kdd-cup-99-data/">KDD Cup 99 Dataおぼえがき</a>
  

      </header>
    
    <time class="article-date" datetime="2016-11-22T21:50:00.000Z" itemprop="datePublished">11-23-2016</time>
    
  </div>
  <div class="article-inner">
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h1><p>　サイバーセキュリティに携わる者なら一度くらいはKDD Cup 99 Dataなるデータセットの名を耳にしたことがあるのではないだろうか．KDD Cupは国際会議SIGKDDによるデータマイニングのコンペで，KDD Cup 99 Dataはそのためのネットワーク侵入検知にまつわるデータ．正常通信と攻撃を分類するタスクが与えられた．<br>　見てみよう．</p>
<h1 id="データセットの構成"><a href="#データセットの構成" class="headerlink" title="データセットの構成"></a>データセットの構成</h1><p>　データは現在，カリフォルニア大学アーバイン校によって<a href="http://archive.ics.uci.edu/ml/databases/kddcup99/kddcup99.html" target="_blank" rel="external">配布</a>されている．<br>　それぞれのファイル内容は下記の通り：</p>
<table>
<thead>
<tr>
<th>ファイル名</th>
<th>ファイル内容</th>
</tr>
</thead>
<tbody>
<tr>
<td>kddcup.data</td>
<td>フルデータ</td>
</tr>
<tr>
<td>kddcup.data_10_percent</td>
<td>フルデータの10%を抽出した学習用データ</td>
</tr>
<tr>
<td>corrected</td>
<td>正常・攻撃のラベル付けがなされた評価用データ</td>
</tr>
<tr>
<td>kddcup.testdata.unlabeled</td>
<td>正常・攻撃のラベル付けがなされていないデータ</td>
</tr>
<tr>
<td>kddcup.testdata.unlabeled_10_percent</td>
<td>正常・攻撃のラベル付けがなされていないデータの10%サブセット</td>
</tr>
<tr>
<td>kddcup.newtestdata_10_percent_unlabeled</td>
<td>正常・攻撃のラベル付けがなされていないデータの10%サブセット</td>
</tr>
</tbody>
</table>
<p>　ファイルの中身はこんな調子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">$ wget -r -l 1 http://kdd.ics.uci.edu/databases/kddcup99/</div><div class="line">$ gunzip -r kdd.ics.uci.edu/kddcup99</div><div class="line">$ ln -s kdd.ics.uci.edu/databases/kddcup99 kddcup99</div><div class="line">$ head -5 kddcup99/kddcup.data</div><div class="line">0,tcp,http,SF,215,45076,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0.00,0.00,0.00,0.00,1.00,0.00,0.00,0,0,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,normal.</div><div class="line">0,tcp,http,SF,162,4528,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,2,2,0.00,0.00,0.00,0.00,1.00,0.00,0.00,1,1,1.00,0.00,1.00,0.00,0.00,0.00,0.00,0.00,normal.</div><div class="line">0,tcp,http,SF,236,1228,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0.00,0.00,0.00,0.00,1.00,0.00,0.00,2,2,1.00,0.00,0.50,0.00,0.00,0.00,0.00,0.00,normal.</div><div class="line">0,tcp,http,SF,233,2032,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,2,2,0.00,0.00,0.00,0.00,1.00,0.00,0.00,3,3,1.00,0.00,0.33,0.00,0.00,0.00,0.00,0.00,normal.</div><div class="line">0,tcp,http,SF,239,486,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,3,3,0.00,0.00,0.00,0.00,1.00,0.00,0.00,4,4,1.00,0.00,0.25,0.00,0.00,0.00,0.00,0.00,normal.</div></pre></td></tr></table></figure>
<p>　これは，ファイルの特徴をカンマ区切りで列挙したもの．列に特徴名を振れば，pandas（や，scikit-learn）での扱いも楽．</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> pandas</div><div class="line"><span class="meta">&gt;&gt;&gt; </span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>col_names = [<span class="string">"duration"</span>,<span class="string">"protocol_type"</span>,<span class="string">"service"</span>,<span class="string">"flag"</span>,<span class="string">"src_bytes"</span>,</div><div class="line"><span class="meta">... </span>   <span class="string">"dst_bytes"</span>,<span class="string">"land"</span>,<span class="string">"wrong_fragment"</span>,<span class="string">"urgent"</span>,<span class="string">"hot"</span>,<span class="string">"num_failed_logins"</span>,</div><div class="line"><span class="meta">... </span>   <span class="string">"logged_in"</span>,<span class="string">"num_compromised"</span>,<span class="string">"root_shell"</span>,<span class="string">"su_attempted"</span>,<span class="string">"num_root"</span>,</div><div class="line"><span class="meta">... </span>   <span class="string">"num_file_creations"</span>,<span class="string">"num_shells"</span>,<span class="string">"num_access_files"</span>,<span class="string">"num_outbound_cmds"</span>,</div><div class="line"><span class="meta">... </span>   <span class="string">"is_host_login"</span>,<span class="string">"is_guest_login"</span>,<span class="string">"count"</span>,<span class="string">"srv_count"</span>,<span class="string">"serror_rate"</span>,</div><div class="line"><span class="meta">... </span>   <span class="string">"srv_serror_rate"</span>,<span class="string">"rerror_rate"</span>,<span class="string">"srv_rerror_rate"</span>,<span class="string">"same_srv_rate"</span>,</div><div class="line"><span class="meta">... </span>   <span class="string">"diff_srv_rate"</span>,<span class="string">"srv_diff_host_rate"</span>,<span class="string">"dst_host_count"</span>,<span class="string">"dst_host_srv_count"</span>,</div><div class="line"><span class="meta">... </span>   <span class="string">"dst_host_same_srv_rate"</span>,<span class="string">"dst_host_diff_srv_rate"</span>,<span class="string">"dst_host_same_src_port_rate"</span>,</div><div class="line"><span class="meta">... </span>   <span class="string">"dst_host_srv_diff_host_rate"</span>,<span class="string">"dst_host_serror_rate"</span>,<span class="string">"dst_host_srv_serror_rate"</span>,</div><div class="line"><span class="meta">... </span>   <span class="string">"dst_host_rerror_rate"</span>,<span class="string">"dst_host_srv_rerror_rate"</span>,<span class="string">"label"</span>]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>kdd_data_10percent = pandas.read_csv(<span class="string">"kddcup99/kddcup.data_10_percent"</span>, header=<span class="keyword">None</span>, names = col_names)</div></pre></td></tr></table></figure>
<p>　学習用データは通常データ，22種類の攻撃データの計23種類のデータからなる．評価用データは，学習用データに加えて17種類の攻撃データを含んでいる．これらの攻撃は4つのクラスに大別される：</p>
<table>
<thead>
<tr>
<th>クラス</th>
<th>説明</th>
<th>サブクラス</th>
</tr>
</thead>
<tbody>
<tr>
<td>Normal</td>
<td>通常のコネクション</td>
<td>normal</td>
</tr>
<tr>
<td>Probe</td>
<td>攻撃対象の探索・調査</td>
<td>ipsweep, nmap, postsweep, satan, mscan, saint</td>
</tr>
<tr>
<td>DoS</td>
<td>DoS攻撃</td>
<td>back, land, neptune, pod, smurf, teardrop, mailbomb, apache2, processtable, udpstorm</td>
</tr>
<tr>
<td>U2R</td>
<td>ローカルマシンからrootへの許可されていないアクセス</td>
<td>buffer.overflow, localmodule, perl, rootkit, httptunnel, xterm, ps, worm</td>
</tr>
<tr>
<td>R2L</td>
<td>リモートマシンからの許可されていないアクセス</td>
<td>ftp_write, guess_passwd, imap, multihop, phf, spy, warezclient, warezmaster, snmpgetattack, snmpguess, xsnoop, named, sendmail, sqlattack, xlock</td>
</tr>
</tbody>
</table>
<p>　サブクラス名から古臭さがにじんでいるが，データセットは近年の研究でも広く用いられているものだ．まあ単純に同規模の新しいデータセットがないからだろう．<br>　だいたいの論文は<code>kddcup.data_10_percent</code>を用いて学習し，<code>corrected</code>を用いて評価するという流れになっている．<br>　ところで，このデータセットに付随したタスクは正常通信と攻撃の二値（まあ多値分類になりはするが）分類だが，これは異常検知とどう違うのだろうか．<a href="https://www.amazon.co.jp/dp/B018K6C99U/" target="_blank" rel="external">ものの本</a>によると，二値分類はベイズ決定則（条件付き分布<span>$p(x|y=1)p(y=1)$</span><!-- Has MathJax -->と<span>$p(x|y=0)p(y=0)$</span><!-- Has MathJax -->の比が1を超えたら異常と判定），異常検知はネイマン・ピアソン決定則（<span>$p(x|y=1)$</span><!-- Has MathJax -->と<span>$p(x|y=0)$</span><!-- Has MathJax -->の比がある閾値を超えたら異常と判定）にもとづいている．ここで，異常検知問題ではほとんどつねに<span>$p(y=1)&lt;&lt;p(y=0)$</span><!-- Has MathJax -->であるため，ベイズ決定則は異常判定を強く抑制する．そういうわけで，標本の割合を吟味して二値分類器の閾値をスライドさせていくことが重要となってくるらしい．</p>
<h1 id="データセット形式への変換"><a href="#データセット形式への変換" class="headerlink" title="データセット形式への変換"></a>データセット形式への変換</h1><p>　<a href="https://github.com/inigoperona/tcpdump2gureKDDCup99" target="_blank" rel="external">tcpdump2gureKDDCup99</a>は，<a href="https://github.com/bro/bro" target="_blank" rel="external">Bro IDS</a>のプラグインとして，おなじみのpcapファイルをKDD Cup 99 Dataのフォーマットに変換してくれる．Bro IDSはSnortには及ばずともそこそこ由緒あるIDSで，GitHubリポジトリは<a href="https://code.gov/#/explore-code/agencies/DOE" target="_blank" rel="external">米国政府公式のリポジトリリスト</a>にも掲載されている．<br>　まずBro IDSをインストールする．</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">$ sudo apt-get install cmake make gcc g++ flex bison libpcap-dev libssl-dev python-dev swig zlib1g-dev</div><div class="line">$ git clone --recursive git://git.bro.org/bro</div><div class="line">$ cd bro</div><div class="line">$ ./configure</div><div class="line">$ make -j4</div><div class="line">$ sudo make install</div></pre></td></tr></table></figure>
<p>　私はpyenvからインストールしたPython 2.7.11を常用しているのだが，Bro IDSをmakeするには<code>CFLAGS=&quot;-fPIC&quot; pyenv install 2.7.11</code>のように共有ライブラリ用のオプションをつけてPythonを再インストールする必要があった．<br>　さてWireshark公式が公開している<a href="https://wiki.wireshark.org/SampleCaptures" target="_blank" rel="external">サンプルデータ</a>をKDD Cup 99 Dataの形式に変換してみる．</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">$ cd</div><div class="line">$ git clone git@github.com:inigoperona/tcpdump2gureKDDCup99</div><div class="line">$ gcc tcpdump2gureKDDCup99/trafAld.c -o tcpdump2gureKDDCup99/trafAld.out</div><div class="line">$ wget &quot;https://wiki.wireshark.org/SampleCaptures?action=AttachFile&amp;do=get&amp;target=zlip-1.pcap&quot; -O zlip-1.pcap</div><div class="line">$ bro -r zlip-1.pcap tcpdump2gureKDDCup99/darpa2gurekddcup.bro &gt; conn.list</div><div class="line">$ cat conn.list</div><div class="line">1 955453631.643199 1024 53 10.0.0.1 146.84.28.88 0.000000 udp 53 S0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</div><div class="line">$ sort -n conn.list &gt; conn_sort.list</div><div class="line">$ tcpdump2gureKDDCup99/trafAld.out conn_sort.list</div><div class="line">$ cat trafAld.list</div><div class="line">1 955453631.643199 1024 53 10.0.0.1 146.84.28.88 0.000000 udp 53 S0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0 0 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000</div></pre></td></tr></table></figure>
<p>　pcapファイルをPythonで分析したければそのまま（scapyや）pandasに突っ込むだろうけど，KDD Cup 99 Dataと比較したい場合には使えるかも．</p>
<h1 id="おわりに"><a href="#おわりに" class="headerlink" title="おわりに"></a>おわりに</h1><p>　名前は聞くけど触ったことないなということで．やらなければならない作業が進まないとこういう現実逃避が捗る捗る．</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li>H. G. Kayacık, et al. <a href="https://web.cs.dal.ca/~zincir/bildiri/pst05-gnm.pdf" target="_blank" rel="external">Selecting Features for Intrusion Detection: A Feature Relevance Analysis on KDD 99 Intrusion Detection Datasets[PDF]</a>. PST. 2005.<ul>
<li>この特徴に注意しようねという論文</li>
</ul>
</li>
<li>高橋，et al. <a href="https://ipsj.ixsq.nii.ac.jp/ej/index.php?active_action=repository_view_main_item_detail&amp;page_id=13&amp;block_id=8&amp;item_id=146854&amp;item_no=1" target="_blank" rel="external">KDD CUP 99 Data Set を用いた異なる学習データによる機械学習アルゴリズムの評価</a>．CSS. pp. 457-464. 2015.<ul>
<li>WekaでランダムフォレストとSVMを試した論文．日本語で読めて便利</li>
</ul>
</li>
<li><a href="https://github.com/jadianes/kdd-cup-99-spark" target="_blank" rel="external">jadianes/kdd-cup-99-spark: PySpark solution to the KDDCup9</a><ul>
<li>iPython Notebookからscikit-learnとPySparkを用いてKDD Cup 99 Dataを分析するデモが試せて便利</li>
</ul>
</li>
</ul>
<p>　はい．</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ntddk.github.io/2016/11/23/kdd-cup-99-data/" data-id="cjkr035si000rpv7twr3xoquw" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/network/">network</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-neural-image-caption-generator-twitter-bot" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    
      <header class="article-header">
        
  
    <a class="article-title" href="/2016/03/26/neural-image-caption-generator-twitter-bot/">写真から説明文を自動生成するbotを作った</a>
  

      </header>
    
    <time class="article-date" datetime="2016-03-25T15:30:00.000Z" itemprop="datePublished">03-26-2016</time>
    
  </div>
  <div class="article-inner">
    <div class="article-entry" itemprop="articleBody">
      
        <p><center><br><a class="twitter-timeline" href="https://twitter.com/img2cap" data-widget-id="713361832895860739" target="_blank" rel="external">@img2capさんのツイート</a></center></p>
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>

<h1 id="これはなに"><a href="#これはなに" class="headerlink" title="これはなに"></a>これはなに</h1><p>　<code>@img2cap file</code>という形式で画像を投げつけると説明文をつけ加えて返信するだけのTwitter bot.</p>
<h1 id="しくみ"><a href="#しくみ" class="headerlink" title="しくみ"></a>しくみ</h1><p>　CNN + LSTM.<br>　以下の論文や実装を参考にした．裏ではChainerが動いている．</p>
<ul>
<li>論文<ul>
<li><a href="http://arxiv.org/abs/1411.4555" target="_blank" rel="external">[1411.4555] Show and Tell: A Neural Image Caption Generator</a></li>
</ul>
</li>
<li>実装<ul>
<li><a href="https://github.com/apple2373/chainer_caption_generation" target="_blank" rel="external">apple2373/chainer_caption_generation: Caption generation from images using deep neural net</a></li>
<li><a href="https://github.com/dsanno/chainer-image-caption" target="_blank" rel="external">dsanno/chainer-image-caption</a></li>
</ul>
</li>
<li>データセット<ul>
<li><a href="http://mscoco.org" target="_blank" rel="external">Microsoft COCO</a>を<a href="https://gist.github.com/ksimonyan/3785162f95cd2d5fee77#file-readme-md" target="_blank" rel="external">VGG_ILSVRC_19_layers</a>で<a href="http://cs.stanford.edu/people/karpathy/deepimagesent/coco.zip" target="_blank" rel="external">学習したもの</a></li>
</ul>
</li>
</ul>
<p>　はじめは論文通りの活性化関数と勾配法を試してみたが，dsanno氏のいうようにSGDよりAdamの方が高速．MomentumSGDと比べてもみたが即Adam最高！　という気分にさせられた．AdamがそもそもAdaGradとRMSPropのいいとこどりらしいので，その両者は試していない．なおネットワーク構成は論文のまま．<br>　データセットに含まれているのは<strong>写真</strong>8万枚とその説明文だけ．よってTwitterの各位がいくらイラストを投げつけようと無駄な話で，その手のニーズに対応するには<a href="https://nico-opendata.jp/ja/index.html" target="_blank" rel="external">ニコニコ静画のデータセット</a>あたりを使う必要がありそう．これには画像とそのタグ，コメントを学習したモデルが含まれているそうだが，説明文の生成というタスクに向けてどう転移学習させるか目処は立っていない．<br>　当然ながら学習データと実際に各位が投げつけてくるデータの分布は全く異なるし，困ったものだ．</p>
<h1 id="謝辞"><a href="#謝辞" class="headerlink" title="謝辞"></a>謝辞</h1><p>　お遊びにGPU環境を貸してくれた<a href="https://twitter.com/georgioush" target="_blank" rel="external">@georgioush</a>, <a href="https://twitter.com/dasoran" target="_blank" rel="external">@dasoran</a>両氏に感謝．</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ntddk.github.io/2016/03/26/neural-image-caption-generator-twitter-bot/" data-id="cjkr035sk000tpv7try7ombg8" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-book-guide-for-computational-neuroscience" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    
      <header class="article-header">
        
  
    <a class="article-title" href="/2016/03/21/book-guide-for-computational-neuroscience/">ニューラルネットと脳の違いが知りたくて</a>
  

      </header>
    
    <time class="article-date" datetime="2016-03-20T15:30:00.000Z" itemprop="datePublished">03-21-2016</time>
    
  </div>
  <div class="article-inner">
    <div class="article-entry" itemprop="articleBody">
      
        <p>　読書メモ．</p>
<h1 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h1><p>　人間の脳を模したニューラルネットの手法，<ruby>深層学習<rt>ディープラーニング</rt></ruby>がめざましい成果を挙げている–といった謳い文句をよく目にする．だが機械学習の専門書を紐解いても出てくるのはロジスティック回帰のお化けばかり．<br>　われらがPRMLのニューラルネットを扱う章にはこうある．</p>
<blockquote>
<p>しかしながら，パターン認識という実際的な応用の観点からは，生物学的な現実性などは全く不要な制約である．<br>　　　　　　　　　　　　　　　　　　　　　　　　– C.M.ビショップ『<a href="http://www.amazon.co.jp/dp/4621061224" target="_blank" rel="external">パターン認識と機械学習 上</a>』 (p.226)</p>
</blockquote>
<p>　では，機械学習の文脈で言うところのニューラルネットと脳はどれほど異なっているのだろうか？</p>
<h1 id="ニューラルネットと脳の違い"><a href="#ニューラルネットと脳の違い" class="headerlink" title="ニューラルネットと脳の違い"></a>ニューラルネットと脳の違い</h1><p>　結論から言えば全然違うわけだが，ざっくり以下の三点から整理できる（と思う）：</p>
<ul>
<li>ニューロンのモデル</li>
<li>ネットワーク構造</li>
<li>微分計算の手法</li>
</ul>
<h2 id="ニューロンのモデル"><a href="#ニューロンのモデル" class="headerlink" title="ニューロンのモデル"></a>ニューロンのモデル</h2><p>　現在広く普及している多層パーセプトロンは，単純な差分方程式であるMcCulloch-Pittsモデルをベースに，層を重ねたとき微分できるような活性化関数を組み合わせている．だがそれ以外にも膜電位が変動するメカニズムを考慮した：</p>
<ul>
<li>Hodgkin-Huxleyモデル</li>
<li>FitzHugh-Nagumoモデル</li>
<li>Izhikevichモデル</li>
</ul>
<p>などが提案されている–というようなことは機械学習の道具としてニューラルネットを扱っている本にはあまり書かれていない．ひとまず手元にあった：</p>
<ul>
<li>はじパタこと『<a href="http://www.amazon.co.jp/dp/4627849710/" target="_blank" rel="external">はじめてのパターン認識</a>』</li>
<li>わかパタこと『<a href="http://www.amazon.co.jp/dp/4274131491/" target="_blank" rel="external">わかりやすいパターン認識</a>』</li>
<li>『<a href="http://www.amazon.co.jp/dp/B016Q22IX2/" target="_blank" rel="external">ITエンジニアのための機械学習理論入門</a>』</li>
<li>PRMLこと『<a href="http://www.amazon.co.jp/dp/4621061224/" target="_blank" rel="external">パターン認識と機械学習</a>』</li>
<li>青色の『<a href="http://www.amazon.co.jp/dp/B018K6C99A/" target="_blank" rel="external">深層学習</a>』</li>
<li>紫色の『<a href="http://www.amazon.co.jp/dp/B01B768QJW/" target="_blank" rel="external">深層学習</a>』</li>
</ul>
<p>はモデル名に言及しておらず，McCulloch-Pittsモデルを紹介していたのは：</p>
<ul>
<li>『<a href="http://www.amazon.co.jp/dp/4274218023/" target="_blank" rel="external">進化計算と深層学習</a>』</li>
<li>『<a href="http://www.amazon.co.jp/dp/406153825X" target="_blank" rel="external">イラストで学ぶディープラーニング</a>』</li>
</ul>
<p>だけだった．<br>　ちなみにこの中だと機械学習マジで何もわからんって人はまずサンプルコードを動かしながら『<a href="http://www.amazon.co.jp/dp/B016Q22IX2/" target="_blank" rel="external">ITエンジニアのための機械学習理論入門</a>』を読むとよい．深層学習については<a href="http://www.amazon.co.jp/dp/B01B768QJW/" target="_blank" rel="external">紫色の本</a>が好み．<a href="http://www.amazon.co.jp/dp/B018K6C99A/" target="_blank" rel="external">青色の本</a>は数式が追いにくい（どっちもどっちだが）上，深層学習以前と以後でどのような変遷があったのか不明瞭で，『<a href="http://www.amazon.co.jp/dp/4274218023/" target="_blank" rel="external">進化計算と深層学習</a>』は概論のみ．『<a href="http://www.amazon.co.jp/dp/406153825X" target="_blank" rel="external">イラストで学ぶディープラーニング</a>』は読みやすく，汎化性能を向上させる方法も載っていて実践的ではあるが，RNNに触れられていないのが惜しい．<br>　さて，それではニューロンのモデルが複雑であれば脳に近いのかというと，どうやらそういうわけでもないらしい．たとえば複雑かつイオンコンダクタンスの挙動が緻密なHodgkin-Huxleyモデルは，ヤリイカの軸索のニューロンをモデル化したものだが，これはヒトの大脳皮質とはタイプが異なるようだ．<br>　しかし，McCulloch-Pittsモデルには，STDP (Spike Timing Dependent Plasticity, スパイク時刻依存シナプス可塑性) を表現できていないという問題点がある．STDPはニューロンの発火タイミングに応じて重みを更新する規則で，脳はこれにより時系列を学習しているとされる．<br>　こういったことを把握するためにいくつか神経科学の本を読んでみた．だいたいの書籍がまず最初にニューロンのモデルを紹介し，それからニューロンの同期に章を割き，つづいて脳の任意の部位の詳説という体裁をとっている．</p>
<ul>
<li>『<a href="http://www.amazon.co.jp/dp/4130643010/" target="_blank" rel="external">脳の計算論</a>』</li>
<li>『<a href="http://www.amazon.co.jp/dp/4130623044/" target="_blank" rel="external">理工学系からの脳科学入門</a>』</li>
<li>『<a href="http://www.amazon.co.jp/dp/B006YKU67M/" target="_blank" rel="external">臨時別冊数理科学 SGCライブラリ 60 「計算神経科学への招待」脳の学習機構の理解を目指して 2007年 12月号</a>』</li>
<li>『<a href="http://www.amazon.co.jp/dp/478281514X/" target="_blank" rel="external">脳の計算理論</a>』</li>
</ul>
<p>など．全部読んだ感想としては『<a href="http://www.amazon.co.jp/dp/4130643010/" target="_blank" rel="external">脳の計算論</a>』が最も明快かつ簡潔で，STDPにも詳しく，この記事で触れている範囲のことはほぼカバーしている．<br>　Izhikevichモデルの考案者も『<a href="http://www.izhikevich.org/publications/dsn/index.htm" target="_blank" rel="external">Dynamical Systems in Neuroscience: The Geometry of Excitability and Bursting</a>』という本を書いているのだが，これは難しそう．<br>　本腰を入れて学ぶには「<a href="http://gaya.jp/research/LTP-papers.htm" target="_blank" rel="external">シナプス可塑性の初心者へ　推薦論文リスト</a>」を消化すべきなのだろう．</p>
<h2 id="ネットワーク構造"><a href="#ネットワーク構造" class="headerlink" title="ネットワーク構造"></a>ネットワーク構造</h2><p>　パーセプトロンは小脳に，BESOMは大脳皮質に，畳み込みニューラルネットは受容野に，TD学習は大脳基底核に似ていると言われている．ではどこが．<br>　小脳についてはさきほど挙げた『<a href="http://www.amazon.co.jp/dp/478281514X/" target="_blank" rel="external">脳の計算理論</a>』がよい．この<a href="http://www.cns.atr.jp/~kawato/Japanese.html" target="_blank" rel="external">著者</a>は小脳による運動の内部モデル獲得というテーマの大家だそうで，公開されている無料のPDFでその足跡が追える．Hodgkin-Huxleyモデルの解説も丁寧．あわせて“<a href="http://ci.nii.ac.jp/naid/10028190905" target="_blank" rel="external">現代の小脳パーセプトロン仮説</a>”も読みたい．<br>　大脳皮質については<a href="https://staff.aist.go.jp/y-ichisugi/j-index.html" target="_blank" rel="external">BESOMの人</a>の「<a href="https://staff.aist.go.jp/y-ichisugi/rapid-memo/brain-deep-learning.html" target="_blank" rel="external">大脳皮質と deep learning の類似点と相違点</a>」がとにかくわかりやすい．やはり正則化が重要なようだが，それについては「<a href="http://blog.livedoor.jp/brain_network/archives/50968197.html" target="_blank" rel="external">脳とネットワーク/The Swingy Brain:まとめてスパースコーディング - livedoor Blog（ブログ）</a>」に挙げられている論文を読むとよさそう．<br>　さらなる部位との関連については，「<a href="https://staff.aist.go.jp/y-ichisugi/brain-archi/j-index.html" target="_blank" rel="external">全脳アーキテクチャ解明に向けて</a>」から辿れる資料が親切だった．特に「<a href="http://www.slideshare.net/sato0427/wba3rd-satonao" target="_blank" rel="external">海馬神経回路の機能ダイナミクス</a>」で触れられている内容は元論文の古さとは裏腹にあまり書籍では見ない．</p>
<h2 id="微分計算の手法"><a href="#微分計算の手法" class="headerlink" title="微分計算の手法"></a>微分計算の手法</h2><p>　みんな大好き誤差逆伝播法は脳では使われていない．じゃあどうすればいいかというと：</p>
<ul>
<li>『<a href="http://www.amazon.co.jp/dp/0262650541" target="_blank" rel="external">Computational Explorations in Cognitive Neuroscience: Understanding the Mind by Simulating the Brain</a>』<ul>
<li>5章</li>
</ul>
</li>
<li>“<a href="http://arxiv.org/abs/1412.7525" target="_blank" rel="external">Difference Target Propagation</a>”<ul>
<li><a href="http://deeplearning.jp/wp-content/uploads/2014/04/20150826_suzuki.pdf" target="_blank" rel="external">日本語の解説</a></li>
</ul>
</li>
<li>“<a href="http://arxiv.org/abs/1502.04156" target="_blank" rel="external">Towards Biologically Plausible Deep Learning</a>”</li>
</ul>
<p>がある．後者2つは深層学習の大家であるBengioらの研究で，ここでSTDPが重要となってくるらしい．生物学的な妥当な深層学習まであと何年だろうか．</p>
<h1 id="おわりに"><a href="#おわりに" class="headerlink" title="おわりに"></a>おわりに</h1><p>　機械学習のことは多少わかるけど（計算論的）神経科学については何から勉強すればいいのかもわからないというところから，騙し騙しとはいえ論文を読める程度になるにはこのあたりを読むとよいのではないかと思います．<br>　なお，このブログに貼られているAmazonリンクはいずれも素のリンクです．ご安心ください．アフィリエイトリンクを貼りまくって小銭を稼ごうと画策しましたが審査に落ちました．</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ntddk.github.io/2016/03/21/book-guide-for-computational-neuroscience/" data-id="cjkr035sd000fpv7to74lsk8d" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-generating-thesis-titles-with-rnnlm" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    
      <header class="article-header">
        
  
    <a class="article-title" href="/2015/12/19/generating-thesis-titles-with-rnnlm/">RNNLMによる論文タイトルの自動生成</a>
  

      </header>
    
    <time class="article-date" datetime="2015-12-19T14:45:00.000Z" itemprop="datePublished">12-19-2015</time>
    
  </div>
  <div class="article-inner">
    <div class="article-entry" itemprop="articleBody">
      
        <p>　本稿は<a href="http://www.adventar.org/calendars/1053" target="_blank" rel="external">慶應義塾大学SFC村井&amp;徳田研 Advent Calendar 2015</a>の19日目である．</p>
<h1 id="TL-DR"><a href="#TL-DR" class="headerlink" title="TL;DR:"></a>TL;DR:</h1><p>　村井研・徳田研の卒論・修論・博論アーカイブから過去の論文タイトルを収集し，RNNLM（Recurrent Neural Network Language Model, 再帰型ニューラルネット言語モデル）[1]を用いて論文タイトルを自動生成する．</p>
<h1 id="手順"><a href="#手順" class="headerlink" title="手順"></a>手順</h1><ol>
<li><a href="http://www.sfc.wide.ad.jp/paper.html" target="_blank" rel="external">論文アーカイブ</a>を雑にスクレイピング．</li>
<li>簡単のため英語タイトルを削る．データサイズは540行・16294字．</li>
<li>MeCabの<code>-Owakati</code>オプションで分かち書き．単語数は6272と少ない．</li>
<li>RNNLMで学習，出力．</li>
</ol>
<p>　生成した論文タイトルは次の通り．</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div></pre></td><td class="code"><pre><div class="line">改変適応機環境におけるインターネット化の設計と実装</div><div class="line">暮らし計算発見を利用したUDL機器</div><div class="line">インターネットを用いた機器プローブ体系のVoDについて開発な攻撃運用手法</div><div class="line">自律計算ネットワークの行動に-移動システムに関する研究</div><div class="line">衛星情報を用いたビジュアライゼーション定義アーキテクチャ表をする検出ユビキタスノードのファイル構成に関する研究</div><div class="line">あしあと適応セキュリティネットワークを用いた負荷議事取り入れたセンサNEMOMANET解決</div><div class="line">ユーザエンティティに適した仮想な通信接近による制御対象の設計と実装</div><div class="line">蓄積学校利用性のための再作業に関する持続</div><div class="line">型連携ネットワークのインターネットに基づく遠隔コードの向けたデジタル機構の構築</div><div class="line">アプリケーション：型と時間特定を用いた利用型路準拠相関の構築</div><div class="line">自律電話教育における異種品質空間支援システムの設計と実装</div><div class="line">位置AV端末著作授業特殊トポロジ型し分析高速構築</div><div class="line">広域を利用した次応用におけるレイヤーな授業に関する研究プロシステムに関する研究</div><div class="line">次制御対するカメラを利用したAd型間屋外パブリック構築</div><div class="line">協調:不sネットワークにおけるOSストリーミングの考慮機器コミュニケーション配信システムの設計と実装</div><div class="line">センサ環境におけるデバイスソフトウェア文字通信システム</div><div class="line">無線作業めぐるにおけるパケットIP発信・支援機構</div><div class="line">ELA上環境に応じたしたコンピュータ測定に関する研究</div><div class="line">インターネット型プラットホームの遠隔パケットとシステム</div><div class="line">無線コントロールセンサを考慮する参加参加サービスの研究</div><div class="line">移動者における位置適応オブジェクト手法の研究</div><div class="line">インターネットグルーピングの回覧性をシステムした経路消耗性の実現</div><div class="line">自己情報を用いた実を量子よる協調表行動流通</div><div class="line">デジタル前遠隔しるしの情報共有支援機構</div><div class="line">ネットワークト可視ネットワークを車的基盤」関数の分析</div><div class="line">環境Computing通信DVB携帯性に関する移動同期利用の設計と実装</div><div class="line">マルチパスFunction無線センサノードを用いた技術マルチ支援支援促進に関する研究</div><div class="line">スマート世代ネットワークにおける相互ブリッジ家電システムの設計と実装</div><div class="line">インターネット情報のための興味無支援システムの構築</div><div class="line">オペレーティング型IP環境のプロファイリング的な信頼に関する研究</div><div class="line">実方向自動ポロジにおける同期機器性における研究</div><div class="line">センサ-抽出生成を支援情報登録抽出機構の構築</div><div class="line">アドホックOSにおけるOS環境のGlass性基盤機構の構築</div><div class="line">DV地アプリケーションの者による最適いアルゴリズム</div><div class="line">商上のための選択なMobile効率システムの構築</div><div class="line">ユビキタス世代環境における効率Wireless情報のMarkit</div><div class="line">系列演奏位置スレッドサービス二マッチングマルチプロアクティブモデルの構築</div><div class="line">パケット適応付け利用を考慮したネットワークブログモデルの設計と実装</div><div class="line">TranS情報環境におけるグループホスト同期への安全履歴と分散</div><div class="line">の情報対象でのMediatorコラボレーションに関する研究</div><div class="line">類似Allシステム</div><div class="line">情報グループを利用するデジタル制御動画像配送システムの構築</div><div class="line">RFIDを利用したネットワークのプラットフォーム転送に関する研究</div><div class="line">周辺上セキュリティにおけるコンテキスト者基無線の提案に関する研究</div><div class="line">Link型服行動RCSにおける効率しない機構</div><div class="line">クラシック型車載インターネットを解決した分散音声なりすましシステム</div><div class="line">Dynamic特徴解析に基づく仮想制御機構の設計と実装</div><div class="line">多段CSMAにおける多様な解析管理機構の設計と実装</div><div class="line">移動機:を用いた-コンテンツシステムの構築</div><div class="line">技術センサ環境におけるホーム化による経路サーバ</div><div class="line">アプリケーション回線に基づく薦環境におけるする作成への行動利用に関する研究</div><div class="line">インターネットを用いたしたな動画ルールに関する研究</div><div class="line">機器協調利用Efficientのネットワーク解決のエンド映像構築</div><div class="line">計算情報を利用した家電抽象の迷い連携への構築</div><div class="line">関連情報教育における動的メールイベント収集の研究</div><div class="line">通知におけるデータベース方式購買によるした状態時間グループに関する研究</div><div class="line">コンテキスト:6のためのための設計と実装</div><div class="line">電子ネットワークのための提案と実装</div><div class="line">自己電話を利用したオブジェクト分散型授業属性制御機構の実現</div><div class="line">ネットワークの抽出化環境の向上圧縮システムの構築</div><div class="line">Networks対戦ネットワークにおける家庭テリトリー手法の構築</div><div class="line">広バイト依存患者のための収集及び積極システム</div><div class="line">IPコンテキスト精度点のデータベース的と-発見環境動画像モデル行動-</div><div class="line">通信作業システムの含む属性センサノード付け可能メディアの提案と開発</div><div class="line">情報世代環境時による最適視点環境機構の設計と実装</div><div class="line">協調蓄積モバイルバッテリ支援Shumu機器型設置インシデントIrma保護量</div><div class="line">分散回線にセンサデータ適応をマッチングと基準化に関する研究</div><div class="line">環境さ時複数用方式と審議に関する研究</div><div class="line">自律リンク環境におけるインターネット・属性品質</div><div class="line">オブジェクトしにおけるインタフェース技法化推薦機構の研究</div><div class="line">インターネットにおける光を用いた最適遠隔支援環境の構築</div><div class="line">モーバイルs利用とへの実現自動手法の設計と実装</div><div class="line">インターネットに適した時端末型TCP型データ基準の内</div><div class="line">インターネットを用いた受信・辞書収集</div><div class="line">DOS的利用環境におけるbased配信システムの構築</div><div class="line">i：と利用した情報モーダルの作成に関する研究</div><div class="line">APIの情報におけるソフトウェアするをシステムの自律</div><div class="line">インターネットを用いたセル内回避手法アプリケーションFunction選択制御機構</div><div class="line">マルチ:ユーザ時のLooking支援競合の参加情報に関する研究</div><div class="line">マルチネットワークによる動的リモコンアーキテクチャの分析に関する研究</div><div class="line">インターネット：文字を含むと対策軽減地理ファイルの構築</div><div class="line">アプリケーションのデジタル行動環境における負荷教育の設計と実装</div><div class="line">移動制御型メディア取り入れたにおける自律トポロジモデルの提案</div><div class="line">日本回線時におけるセンサのアーキテクチャ</div><div class="line">『世代sionを支援情報ユーザの実現</div><div class="line">Mobileの行動空間に基づくするコンポーネントシステムの設計と構築</div><div class="line">キットライブラリのアドレス利用を支援するアプリケーションの行動に関する研究</div><div class="line">間:環境における認証検出の考察</div><div class="line">鍵盤を用いた基盤経路トポロジ支援手法の研究</div><div class="line">RFIDネットワークを用いたとユーザ</div><div class="line">自律型機的な支援レイヤー手法の設計と実装</div><div class="line">アドホックを用いたデジタル最適暗号システムの研究</div><div class="line">WWW人IPvシステムの動的2を化フローインフォメーション配送化手法</div><div class="line">次的機タフェース6システムの実現</div><div class="line">IPレイヤーネットワークにおけるグループ取得遠隔システムに関する研究</div><div class="line">二通信ユニバーサルにおける複数共有再についての研究</div><div class="line">Tapirus上の情報的実現あるの構築</div><div class="line">環境上における仮想指機構の構築</div><div class="line">インターネットにおけるRFID経路エンドノードデータベース付けモデルの設計と実装</div><div class="line">2回線学習への効率的型環境の提案と構築</div><div class="line">...</div></pre></td></tr></table></figure>
<p>　これはRNNLMが生成した論文タイトルを100件無作為抽出したもの．全リストは<a href="https://gist.github.com/ntddk/c1dd4476677667157a97" target="_blank" rel="external">gist</a>に置いている．この程度のデータサイズでRNNLMの性能を云々するのはいささか危うい気がするが，論文タイトルの末尾はえてして「～の構築」「～の研究」「～の実現」になるというルールを獲得できている，ということだろうか．<br>　同じデータセットから，ありがちな2単語プリフィックスのマルコフ連鎖で生成した論文タイトルは次の通り．</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">注目した二点間接続基盤ソフトウエアの構築インターネット</div><div class="line">地域における高等教育協力手法の研究ホームネットワークにおける多様</div><div class="line">かつスケーラブルな識別子管理システムゲームコンソールに対応する管理</div><div class="line">運用基盤分析に関する研究ポリシ経路制御に関する研究大</div><div class="line">任意の物理的量子ビットに対する効率的な情報閲覧</div><div class="line">脳疲労検知システムの提案次世代インターネット経路制御を用い</div><div class="line">鍵交換機構の実装と評価初等中等教育におけるWWW</div><div class="line">プロセスデザイン片方向ブロードキャストメディアを用いたユビキタスコンピューティング環境に適し</div><div class="line">連携システムの設計と実装exPhoto:周辺機器と撮影</div><div class="line">に関する研究分散環境におけるプロアクティブ制御方式に関する研究アドホック</div><div class="line">...</div></pre></td></tr></table></figure>
<p>　パッと見でRNNLMが生成した論文タイトルの方がより自然に思える．で，RNNLMって何なの？</p>
<h1 id="RNNLM"><a href="#RNNLM" class="headerlink" title="RNNLM"></a>RNNLM</h1><p>　読んで字のごとくRNNLMはRNNの言語モデルへの応用である．<br>　RNNは内部に有向閉路をもつニューラルネット．系列データの各時刻<span>$t$</span><!-- Has MathJax -->につき1つの入力<span>$x^t$</span><!-- Has MathJax -->をとり1つの出力<span>$y^t$</span><!-- Has MathJax -->を返す．ふつう順伝播型ニューラルネットは入力1つをとり1つの入力を与える写像を表現するが，RNNは任意の系列–すなわち過去のすべての入力から任意の系列への写像を表現する．<br>　これは<strong>時刻<span>$t-1$</span><!-- Has MathJax -->の隠れ層の出力を，時刻<span>$t$</span><!-- Has MathJax -->の隠れ層の入力に与える</strong>ことで実現される．</p>
<p><img src="/image/rnnlm/rnnlm.png" width="30%" height="30%"></p>
<p>　文章は系列データであり，文章に含まれる各単語は直前の単語の並びに依存している．そこで，1990年のエルマンネット[2]以来，RNNを用いた文章の分析が試みられてきた–近頃「RNNは深層学習の一種」というような言辞を見かけるが，RNN<span>$\in$</span><!-- Has MathJax -->深層学習では<strong>ない</strong>．<br>　RNNLMと既存手法との相違点は，単語を潜在空間に写像して単語の意味を獲得しようとしているところだ．<br>　上図において隠れ層のベクトルは単語の潜在ベクトルとその履歴より<span>$\begin{split}s(t) =&amp; f(Uw(t) + Ws(t-1))\end{split}$</span><!-- Has MathJax -->となる．次の単語の確率は<span>$\begin{split}y(t) =&amp; g(Vs(t))\end{split}$</span><!-- Has MathJax -->となる．<br>　ここで活性化関数<span>$f(z)$</span><!-- Has MathJax -->は標準シグモイド関数で，<span>$g(z)$</span><!-- Has MathJax -->はソフトマックス関数<span>$\dfrac {e^{zm}} {\Sigma _{k}e^{zm}}$</span><!-- Has MathJax -->である．<br>　学習では確率的勾配降下法を用いて重み<span>$U$</span><!-- Has MathJax -->, <span>$W$</span><!-- Has MathJax -->, <span>$V$</span><!-- Has MathJax -->を更新していくが，このときRNNLMは各層を時間方向に展開し，最後の時刻<span>$t$</span><!-- Has MathJax -->から誤差逆伝播計算をおこなう（BPTT, Backpropagation through time法）．<br>　ここにおいてRNNは多層の順伝播型ニューラルネットのようにみなせる．</p>
<p><img src="/image/rnnlm/bptt.png" width="30%" height="30%"></p>
<p>　BPTT法において，ある時刻<span>$t$</span><!-- Has MathJax -->における出力層の誤差は正解ベクトル<span>$d(t)$</span><!-- Has MathJax -->から出力<span>$y(t)$</span><!-- Has MathJax -->を引いた出力誤差<span>$e_{o}(t)$</span><!-- Has MathJax -->と，時刻<span>$t+1$</span><!-- Has MathJax -->から伝播してきた誤差の和となる．ここでたとえば<span>$V(t+1) = V(t) + s(t)e_{o}(t)^t\alpha - V(t)\beta$</span><!-- Has MathJax -->．<span>$\alpha$</span><!-- Has MathJax -->は学習率であり，各層で行列の勾配に掛かる．<span>$\beta$</span><!-- Has MathJax -->はL2正則化の係数．<br>　このBPTT法で長い系列を扱うとき勾配が消失してしまう問題[3]があり，解決策としてLSTM（Long Short-Term Memory, 長・短期記憶）[4]が提案されているが，割愛する．<br>　なお今回のパラメータは次の通り．</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">last probability of validation data: -441.610349</div><div class="line">number of finished iterations: 14</div><div class="line">current position in training data: 0</div><div class="line">current probability of training data: -441.576456</div><div class="line">save after processing # words: 0</div><div class="line"># of training words: 6272</div><div class="line">input layer size: 1295</div><div class="line">hidden layer size: 200</div><div class="line">compression layer size: 0</div><div class="line">output layer size: 1096</div><div class="line">direct connections: 0</div><div class="line">direct order: 3</div><div class="line">bptt: 6</div><div class="line">bptt block: 10</div><div class="line">vocabulary size: 1095</div><div class="line">class size: 1</div><div class="line">old classes: 0</div><div class="line">independent sentences mode: 1</div><div class="line">starting learning rate: 0.100000</div><div class="line">current learning rate: 0.000195</div><div class="line">learning rate decrease: 1</div></pre></td></tr></table></figure>
<h1 id="おわりに"><a href="#おわりに" class="headerlink" title="おわりに"></a>おわりに</h1><p>　恥知らずのクソ野郎なので何番煎じともわからない記事を書いてしまった．元ネタは<a href="http://www.phontron.com/nlp-title/" target="_blank" rel="external">NLP論文ネタ一覧</a>．<br>　このほか青空文庫やなろう小説[5]をRNNに学習させてはいるが，LSTM込みでもいまだ人間が見て自然に思える文章の生成は難しく思える．<br>　いずれは論文タイトルばかりか論文の内容も自動生成して知の欺瞞をもう一発カマしたいのだが．SFC自体が知の欺瞞っぽいところはさておき．<br>　物語の自動生成なら円城塔がなんとかしてくれるだろう．</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li>[1] “RNNLM Toolkit,” <a href="http://rnnlm.org/" target="_blank" rel="external">http://rnnlm.org/</a><ul>
<li>記事中の画像は開発者による<a href="http://www.fit.vutbr.cz/~imikolov/rnnlm/google.pdf" target="_blank" rel="external">紹介スライド</a>より．</li>
<li>解説は<a href="http://kiyukuta.github.io/2013/12/09/mlac2013_day9_recurrent_neural_network_language_model.html" target="_blank" rel="external">これもある意味Deep Learning，Recurrent Neural Network Language Modelの話 [MLAC2013_9日目] – KiyuHu</a>がわかりやすい．</li>
</ul>
</li>
<li>[2] Jeffrey L. Elman, “<a href="http://crl.ucsd.edu/~elman/Papers/fsit.pdf" target="_blank" rel="external">Finding Structure in Time[PDF]</a>,” Cognitive Science, vol. 14, issue. 2, pp. 179-211, 1990.</li>
<li>[3] Sepp Hochreiter, “<a href="http://www.bioinf.jku.at/publications/older/3804.pdf" target="_blank" rel="external">Untersuchungen zu dynamischen neuronalen Netzen[PDF]</a>,” Diploma thesis, TU Munich, 1991.<ul>
<li>読めない．</li>
</ul>
</li>
<li>[4] Sepp Hochreiter and Jürgen Schmidhuber, “<a href="http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf" target="_blank" rel="external">Long Short-Term Memory[PDF]</a>,” Neural Computation, vol. 9, no. 8, pp. 1735-1780, 1997.<ul>
<li>解説は<a href="http://qiita.com/t_Signull/items/21b82be280b46f467d1b" target="_blank" rel="external">MachineLearning - わかるLSTM ～ 最近の動向と共に - Qiita</a>がわかりやすい．</li>
</ul>
</li>
<li>[5] <a href="http://ncode.syosetu.com/n9073ca/" target="_blank" rel="external">幻想再帰のアリュージョニスト</a>，おすすめです．</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ntddk.github.io/2015/12/19/generating-thesis-titles-with-rnnlm/" data-id="cjkr035sm0010pv7tuybjzqsy" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
  
</section>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 ntddk<br>
      <a href="https://github.com/ntddk/hexo-theme-jathena" target="_blank">JAthena</a> by <a href="https://ntddk.github.io" target="_blank">ntddk</a> | Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>
  </div>

<!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
</body>
</html>